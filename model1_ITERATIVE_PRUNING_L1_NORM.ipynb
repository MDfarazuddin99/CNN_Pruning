{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1_ITERATIVE_PRUNING_L1_NORM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "28-i7Gn_7BK2",
        "colab_type": "code",
        "outputId": "3e4f9a59-24a5-4e6f-876b-4bab8ba4aadd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "!pip install kerassurgeon\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from keras.models import load_model\n",
        "from kerassurgeon import identify \n",
        "from kerassurgeon.operations import delete_channels,delete_layer\n",
        "from kerassurgeon import Surgeon"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kerassurgeon\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/e7/8adbef95f56e2349bf9faf2aec462dee0a38cec7cd6bfb8895de83706762/kerassurgeon-0.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from kerassurgeon) (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.17.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.12.0)\n",
            "Installing collected packages: kerassurgeon\n",
            "Successfully installed kerassurgeon-0.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pDzqntt7bh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "37e00242-61a4-4ee1-dd41-6e95b3836264"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "\n",
        "def normalize(x_train,x_test):\n",
        "    mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "    std = np.std(x_train, axis=(0, 1, 2, 3))\n",
        "    x_train = (x_train-mean)/(std+1e-7)\n",
        "    x_test = (x_test-mean)/(std+1e-7)\n",
        "    return x_train, x_test\n",
        "\n",
        "\n",
        "x_train , x_test = normalize(x_train,x_test)\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faLOoxIR7dnW",
        "colab_type": "code",
        "outputId": "9708d46b-4e63-43fa-f437-23ebdcb7fdab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "\n",
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "model_1.add(Conv2D(32,(3,3),activation='relu',input_shape=x_train.shape[1:]))\n",
        "\n",
        "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_1.add(Conv2D(32,(3,3),activation='relu'))\n",
        "\n",
        "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_1.add(Conv2D(64,(3,3),activation='relu'))\n",
        "\n",
        "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_1.add(GlobalAveragePooling2D())\n",
        "model_1.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model_2 = Sequential()\n",
        "model_2.add(Conv2D(32, (3, 3), padding='same',activation='relu',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "model_2.add(Conv2D(32, (3, 3),activation='relu'))\n",
        "\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
        "\n",
        "model_2.add(Conv2D(64, (3, 3),activation='relu',))\n",
        "\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(512,activation='relu',))\n",
        "\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(10,activation='softmax',))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRMM2dAx7owO",
        "colab_type": "code",
        "outputId": "39adc01e-8ed6-4cc7-c407-43318ad6c285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "my_model = model_1\n",
        "my_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 29,290\n",
            "Trainable params: 29,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QdZXwjy7rQ2",
        "colab_type": "code",
        "outputId": "c0b6dfc4-9d12-47f1-c1ea-83ed7e7cd4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "source": [
        "my_model = load_model('drive/My Drive/Colab Notebooks/model1_before_pruning.h5')\n",
        "score_train = my_model.evaluate(x_train,y_train) \n",
        "\n",
        "print('Accuracy on the Train Images: ', score_train[1])\n",
        "\n",
        "score_test = my_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Accuracy on the Test Images: ', score_test[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 19s 375us/step\n",
            "Accuracy on the Train Images:  0.73128\n",
            "10000/10000 [==============================] - 4s 370us/step\n",
            "Accuracy on the Test Images:  0.6894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DIyLX-i7wDp",
        "colab_type": "code",
        "outputId": "9bd11197-d46b-4403-d58c-7ffce604478e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def my_get_all_conv_layers(model,first_time):\n",
        "    all_conv_layers = list()\n",
        "    for i,each_layer in enumerate(model.layers):\n",
        "        if (each_layer.name[0:6] == 'conv2d'):\n",
        "            all_conv_layers.append(i)\n",
        "\n",
        "    return all_conv_layers if (first_time==True) else all_conv_layers[1:]\n",
        "\n",
        "def my_get_all_dense_layers(model):\n",
        "    all_dense_layers = list()\n",
        "    for i,each_layer in enumerate(model.layers):\n",
        "        if (each_layer.name[0:5] == 'dense'):\n",
        "            all_dense_layers.append(i)\n",
        "    return all_dense_layers\n",
        "\n",
        "\n",
        "all_dense_layers = my_get_all_dense_layers(my_model)\n",
        "\n",
        "all_conv_layers = my_get_all_conv_layers(my_model,True)\n",
        "\n",
        "print('All convolution layers = ',all_conv_layers,'\\nAll dense layers = ',all_dense_layers)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All convolution layers =  [0, 2, 4] \n",
            "All dense layers =  [7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbqBLwPg8HYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_in_conv_layers_get_L1_norms_sorted_indices_and_values(model,graph,first_time):\n",
        "    weights = list()\n",
        "    all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "    for i in all_conv_layers:\n",
        "        print('{}th layer'.format(i),all_conv_layers)\n",
        "        weights.append(model.layers[i].get_weights()[0])\n",
        "    layer_wise_filter_sorted_indices = list()\n",
        "    layer_wise_filter_sorted_values = list()\n",
        "    for i in range(len(weights)):\n",
        "        weight = weights[i]\n",
        "        num_filters = len(weight[0,0,0,:])\n",
        "        # print(num_filters)\n",
        "        weights_dict = dict() \n",
        "        for j in range(num_filters):\n",
        "            weights_sum = np.sum(abs(weight[:,:,:,j]))\n",
        "            filtr = 'filter {}'.format(j)\n",
        "            weights_dict[filtr] = weights_sum\n",
        "        \n",
        "        weights_dict_sorted = sorted(weights_dict.items(),key = lambda kv:kv[1]) \n",
        "        # print('L1 norm of conv2D_{} layer'.format(i+1),weights_dict_sorted)\n",
        "\n",
        "        weight_values = list()\n",
        "        filter_indices = list()\n",
        "\n",
        "        for element in weights_dict_sorted:\n",
        "            filter_indices.append(int(element[0][6:]))  # extracting the index of filter from string (tentative try to come up with better code)\n",
        "            weight_values.append(element[1]) \n",
        "    \n",
        "        layer_wise_filter_sorted_indices.append(filter_indices)\n",
        "        layer_wise_filter_sorted_values.append(weight_values)\n",
        "\n",
        "        if graph == True:\n",
        "                x = np.arange(num_filters)\n",
        "                plt.figure(i+1,figsize=(7,5))\n",
        "                plt.plot(x,np.array(weight_values))\n",
        "                plt.axhline(y=np.mean(np.array(weight_values)),c='r')\n",
        "                for j in range(len(layer_wise_filter_sorted_values[i])):\n",
        "                    if(np.mean(np.array(weight_values)) < weight_values[j]):\n",
        "                        plt.axvline(x=j,c='r')\n",
        "                        break\n",
        "\n",
        "                plt.xlabel('filter number')\n",
        "                plt.ylabel('L1 norm')\n",
        "                plt.title('Conv2d_{}'.format(i+1))\n",
        "                plt.grid(True)\n",
        "                plt.style.use(['classic'])\n",
        "    return layer_wise_filter_sorted_indices,layer_wise_filter_sorted_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ky7PA4f8Jwc",
        "colab_type": "code",
        "outputId": "703896c6-f882-417b-927e-701239097b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def my_get_prune_filter_indices(model,first_time ):\n",
        "    layer_wise_filter_sorted_indices,layer_wise_filter_sorted_values = my_in_conv_layers_get_L1_norms_sorted_indices_and_values(model, False,first_time)\n",
        "    all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "    thresh_hold_means = list()\n",
        "    for i in range(len(all_conv_layers)):\n",
        "        # print(i,'/',len(all_conv_layers))\n",
        "        thresh_hold_means.append(np.mean(np.array(layer_wise_filter_sorted_values[i])))\n",
        "    prune_filter_indices = list()\n",
        "    for i in range(len(all_conv_layers)):\n",
        "        for j in range(len(layer_wise_filter_sorted_values[i])):\n",
        "            if(thresh_hold_means[i] < layer_wise_filter_sorted_values[i][j]):\n",
        "                prune_filter_indices.append(j)\n",
        "                break\n",
        "    return prune_filter_indices\n",
        "prune_filter_indices = my_get_prune_filter_indices(my_model,True)\n",
        "prune_filter_indices"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0th layer [0, 2, 4]\n",
            "2th layer [0, 2, 4]\n",
            "4th layer [0, 2, 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[17, 11, 18]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfo9vugI8NsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_delete_filters(model,first_time):\n",
        "    layer_wise_filter_sorted_indices,layer_wise_filter_sorted_values = my_in_conv_layers_get_L1_norms_sorted_indices_and_values(model,False,first_time)\n",
        "    prune_filter_indices = my_get_prune_filter_indices(model,first_time)\n",
        "    all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "    print(all_conv_layers)\n",
        "    surgeon = Surgeon(my_model)\n",
        "    for index,value in enumerate(all_conv_layers):\n",
        "        print(value,index,prune_filter_indices[index])\n",
        "        surgeon.add_job('delete_channels',model.layers[value],channels = layer_wise_filter_sorted_indices[index][0:prune_filter_indices[index]])\n",
        "    model_new = surgeon.operate()\n",
        "    return model_new\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T7VThPJVz3B",
        "colab_type": "code",
        "outputId": "520dd2ca-460c-4c76-8285-cb48676a7e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "m = my_delete_filters(my_model,first_time = True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0th layer [0, 2, 4]\n",
            "2th layer [0, 2, 4]\n",
            "4th layer [0, 2, 4]\n",
            "0th layer [0, 2, 4]\n",
            "2th layer [0, 2, 4]\n",
            "4th layer [0, 2, 4]\n",
            "[0, 2, 4]\n",
            "0 0 17\n",
            "2 1 11\n",
            "4 2 18\n",
            "Deleting 17/32 channels from layer: conv2d_1\n",
            "Deleting 11/32 channels from layer: conv2d_2\n",
            "Deleting 18/64 channels from layer: conv2d_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6vu7YV38QIe",
        "colab_type": "code",
        "outputId": "216b7f70-a1ea-485d-ab09-3f6e94fb1563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model_new = load_model('drive/My Drive/Colab Notebooks/model1_just_after_pruning.h5')\n",
        "model_new.summary()\n",
        "print(my_get_all_conv_layers(model_new,True))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 15)        420       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 15)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 21)        2856      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 21)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 46)          8740      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 46)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 46)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                470       \n",
            "=================================================================\n",
            "Total params: 12,486\n",
            "Trainable params: 12,486\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[0, 1, 3, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL6FfMNZJSE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# surgeon = Surgeon(model_new)\n",
        "# surgeon.add_job('delete_channels',model_new.layers[1],channels = np.arange(5))\n",
        "# surgeon.add_job('delete_channels',model_new.layers[3],channels = np.arange(5))\n",
        "# model_new = surgeon.operate()\n",
        "# print(my_get_all_conv_layers(model_new,False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OJ1KPasMAAj",
        "colab_type": "code",
        "outputId": "1b8ab733-1493-4d62-b77c-079d62448d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "model_new.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 15)        420       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 15)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 21)        2856      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 21)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 46)          8740      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 46)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 46)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                470       \n",
            "=================================================================\n",
            "Total params: 12,486\n",
            "Trainable params: 12,486\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xNt-tdb8Uua",
        "colab_type": "code",
        "outputId": "d016ae5d-f7af-4e45-ed4f-0a4583a207cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "score_train = model_new.evaluate(x_train,y_train) \n",
        "\n",
        "print('Accuracy on the Train Images: ', score_train[1])\n",
        "\n",
        "score_test = model_new.evaluate(x_test, y_test)\n",
        "\n",
        "print('Accuracy on the Test Images: ', score_test[1])\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 349us/step\n",
            "Accuracy on the Train Images:  0.22772\n",
            "10000/10000 [==============================] - 3s 345us/step\n",
            "Accuracy on the Test Images:  0.2183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9c1uocZ8Y6b",
        "colab_type": "code",
        "outputId": "8f85324a-c391-47d7-f968-bafebf6a158f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model_new = load_model('drive/My Drive/Colab Notebooks/model1_after_training_pruned_model.h5')\n",
        "\n",
        "score_train = model_new.evaluate(x_train,y_train) \n",
        "\n",
        "print('Accuracy on the Train Images: ', score_train[1])\n",
        "\n",
        "score_test = model_new.evaluate(x_test, y_test)\n",
        "\n",
        "print('Accuracy on the Test Images: ', score_test[1])\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 17s 342us/step\n",
            "Accuracy on the Train Images:  0.73522\n",
            "10000/10000 [==============================] - 4s 368us/step\n",
            "Accuracy on the Test Images:  0.6834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6JQ75918c0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = my_delete_filters(my_model,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwVWXsIOBMCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_get_all_conv_layers(model1,False)\n",
        "\n",
        "# model2 = my_delete_filters(model1,False) \n",
        "\n",
        "# my_get_all_conv_layers(model_new,False)\n",
        "# model_new.summary()\n",
        "# a,b = my_in_conv_layers_get_L1_norms_sorted_indices_and_values(model_new,graph = False,first_time = False)\n",
        "# for i in a:\n",
        "#     print(i)\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfqdGS8fMfHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_in_conv_layers_get_L1_norms_sorted_indices_and_values(model1,graph=True,first_time = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8gzJBN9MppZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_get_prune_filter_indices(model1,False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOelpgZKH_t3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "surgeon = Surgeon(model1)\n",
        "surgeon.add_job('delete_channels',model1.layers[1],channels = np.arange(5))\n",
        "model2 = surgeon.operate()\n",
        "model2.summary()\n",
        "print(model1.layers[1].name,model1.layers[3].name,model1.layers[5].name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcanX_7XOB_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_delete_filters(model1,False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Md7qC2pa6Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7M-jOu7bKKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIE2mrZl-gen",
        "colab_type": "code",
        "outputId": "ece2e9c5-5b29-46c5-b7df-b8e54bce4ce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model= load_model('drive/My Drive/Colab Notebooks/model1_before_pruning.h5')\n",
        "\n",
        "\n",
        "validation_accuracy = model.evaluate(x_test,y_test)[1]\n",
        "print(validation_accuracy)\n",
        "max_val_acc = validation_accuracy\n",
        "count = 0\n",
        "while abs(max_val_acc - validation_accuracy)<= 0.05 :\n",
        "    print(count)\n",
        "    if max_val_acc < validation_accuracy:\n",
        "        max_val_acc = validation_accuracy\n",
        "\n",
        "    if count < 1:\n",
        "        model = my_delete_filters(my_model,True)\n",
        "        \n",
        "    else:\n",
        "        conv_layers = my_get_all_conv_layers(model,False)\n",
        "        a,b = my_in_conv_layers_get_L1_norms_sorted_indices_and_values(model,False,False)\n",
        "        thresholds = my_get_prune_filter_indices(model,False)\n",
        "        \n",
        "        surgeon = Surgeon(model)\n",
        "        for index,value in enumerate(conv_layers):\n",
        "            # print(value,index,prune_filter_indices[index])\n",
        "            surgeon.add_job('delete_channels',model.layers[value],channels = a[index][0:thresholds[index]])\n",
        "        model = surgeon.operate()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1, validation_split=0.2, shuffle=True)\n",
        "    validation_accuracy = model.evaluate(x_test,y_test)[1]\n",
        "    print(\"--->\",validation_accuracy)\n",
        "    count+=1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 393us/step\n",
            "0.6894\n",
            "0\n",
            "0th layer [0, 2, 4]\n",
            "2th layer [0, 2, 4]\n",
            "4th layer [0, 2, 4]\n",
            "0th layer [0, 2, 4]\n",
            "2th layer [0, 2, 4]\n",
            "4th layer [0, 2, 4]\n",
            "[0, 2, 4]\n",
            "0 0 17\n",
            "2 1 11\n",
            "4 2 18\n",
            "Deleting 17/32 channels from layer: conv2d_1\n",
            "Deleting 11/32 channels from layer: conv2d_2\n",
            "Deleting 18/64 channels from layer: conv2d_3\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 37s 930us/step - loss: 1.0138 - acc: 0.6468 - val_loss: 1.0475 - val_acc: 0.6449\n",
            "Epoch 2/10\n",
            "40000/40000 [==============================] - 37s 914us/step - loss: 0.8792 - acc: 0.6940 - val_loss: 0.9423 - val_acc: 0.6710\n",
            "Epoch 3/10\n",
            "40000/40000 [==============================] - 36s 903us/step - loss: 0.8393 - acc: 0.7087 - val_loss: 0.9219 - val_acc: 0.6768\n",
            "Epoch 4/10\n",
            "40000/40000 [==============================] - 36s 901us/step - loss: 0.8124 - acc: 0.7154 - val_loss: 0.9188 - val_acc: 0.6845\n",
            "Epoch 5/10\n",
            "40000/40000 [==============================] - 36s 906us/step - loss: 0.7916 - acc: 0.7238 - val_loss: 0.9617 - val_acc: 0.6725\n",
            "Epoch 6/10\n",
            "40000/40000 [==============================] - 38s 947us/step - loss: 0.7727 - acc: 0.7320 - val_loss: 0.9206 - val_acc: 0.6854\n",
            "Epoch 7/10\n",
            "40000/40000 [==============================] - 38s 945us/step - loss: 0.7581 - acc: 0.7347 - val_loss: 0.8985 - val_acc: 0.6967\n",
            "Epoch 8/10\n",
            "40000/40000 [==============================] - 37s 929us/step - loss: 0.7403 - acc: 0.7431 - val_loss: 0.8902 - val_acc: 0.6979\n",
            "Epoch 9/10\n",
            "40000/40000 [==============================] - 37s 915us/step - loss: 0.7273 - acc: 0.7468 - val_loss: 0.9037 - val_acc: 0.6934\n",
            "Epoch 10/10\n",
            "40000/40000 [==============================] - 37s 913us/step - loss: 0.7187 - acc: 0.7510 - val_loss: 0.9000 - val_acc: 0.6971\n",
            "10000/10000 [==============================] - 3s 336us/step\n",
            "---> 0.6984\n",
            "1\n",
            "1th layer [1, 3, 5]\n",
            "3th layer [1, 3, 5]\n",
            "5th layer [1, 3, 5]\n",
            "1th layer [1, 3, 5]\n",
            "3th layer [1, 3, 5]\n",
            "5th layer [1, 3, 5]\n",
            "Deleting 8/15 channels from layer: conv2d_1\n",
            "Deleting 14/21 channels from layer: conv2d_2\n",
            "Deleting 25/46 channels from layer: conv2d_3\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 29s 730us/step - loss: 1.6371 - acc: 0.4044 - val_loss: 1.4297 - val_acc: 0.4893\n",
            "Epoch 2/10\n",
            "40000/40000 [==============================] - 28s 708us/step - loss: 1.3726 - acc: 0.5084 - val_loss: 1.3278 - val_acc: 0.5230\n",
            "Epoch 3/10\n",
            "40000/40000 [==============================] - 29s 714us/step - loss: 1.3057 - acc: 0.5324 - val_loss: 1.3098 - val_acc: 0.5284\n",
            "Epoch 4/10\n",
            "40000/40000 [==============================] - 29s 725us/step - loss: 1.2648 - acc: 0.5486 - val_loss: 1.2911 - val_acc: 0.5402\n",
            "Epoch 5/10\n",
            "40000/40000 [==============================] - 29s 721us/step - loss: 1.2395 - acc: 0.5598 - val_loss: 1.2625 - val_acc: 0.5495\n",
            "Epoch 6/10\n",
            "40000/40000 [==============================] - 29s 720us/step - loss: 1.2189 - acc: 0.5656 - val_loss: 1.2459 - val_acc: 0.5520\n",
            "Epoch 7/10\n",
            "40000/40000 [==============================] - 29s 721us/step - loss: 1.2009 - acc: 0.5739 - val_loss: 1.2330 - val_acc: 0.5619\n",
            "Epoch 8/10\n",
            "40000/40000 [==============================] - 29s 725us/step - loss: 1.1900 - acc: 0.5790 - val_loss: 1.2306 - val_acc: 0.5644\n",
            "Epoch 9/10\n",
            "40000/40000 [==============================] - 29s 724us/step - loss: 1.1785 - acc: 0.5812 - val_loss: 1.2081 - val_acc: 0.5704\n",
            "Epoch 10/10\n",
            "40000/40000 [==============================] - 29s 735us/step - loss: 1.1669 - acc: 0.5851 - val_loss: 1.2054 - val_acc: 0.5756\n",
            "10000/10000 [==============================] - 3s 317us/step\n",
            "---> 0.572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HGXqHboBuvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRn9juI_eStS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNBvm1R4eZWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}