{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet5_MNIST_EUCLIDEAN_DISTANCE_PRUNING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDfarazuddin99/CNN_Pruning/blob/master/LeNet5_MNIST_EUCLIDEAN_DISTANCE_PRUNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiuqUfkbutTN",
        "colab_type": "code",
        "outputId": "9c56f262-dcd2-4e41-8005-8760bb70dcc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAvZwpu-9IP",
        "colab_type": "code",
        "outputId": "0ccc921d-d2c3-4374-e7c1-733cba764c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "# !pip install tesnsorflow 1.x\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D,BatchNormalization,Activation,AveragePooling2D\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "!pip install kerassurgeon\n",
        "from kerassurgeon import identify \n",
        "from kerassurgeon.operations import delete_channels,delete_layer\n",
        "from kerassurgeon import Surgeon"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kerassurgeon in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from kerassurgeon) (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.18.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz5XrgH0_Xod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_get_all_conv_layers(model , first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> type boolean \n",
        "            first_time = True => model is not pruned \n",
        "            first_time = False => model is pruned\n",
        "    Return:\n",
        "        List of Indices containing convolution layers\n",
        "    '''\n",
        "\n",
        "    all_conv_layers = list()\n",
        "    for i,each_layer in enumerate(model.layers):\n",
        "        if (each_layer.name[0:6] == 'conv2d'):\n",
        "            all_conv_layers.append(i)\n",
        "    return all_conv_layers if (first_time==True) else all_conv_layers[1:]\n",
        "\n",
        "\n",
        "def my_get_all_dense_layers(model):\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model        \n",
        "    Return:\n",
        "        List of Indices containing fully connected layers\n",
        "    '''\n",
        "    all_dense_layers = list()\n",
        "    for i,each_layer in enumerate(model.layers):\n",
        "        if (each_layer.name[0:5] == 'dense'):\n",
        "            all_dense_layers.append(i)\n",
        "    return all_dense_layers\n",
        "\n",
        "\n",
        "\n",
        "def my_get_weights_in_conv_layers(model,first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> boolean variable\n",
        "            first_time = True => model is not pruned \n",
        "            first_time = False => model is pruned\n",
        "    Return:\n",
        "        List containing weight tensors of each layer\n",
        "    '''\n",
        "    weights = list()\n",
        "    all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "    layer_wise_weights = list() \n",
        "    for i in all_conv_layers:\n",
        "          weights.append(model.layers[i].get_weights()[0])  \n",
        "    return weights\n",
        "\n",
        "def my_get_l1_norms_filters_per_epoch(weight_list_per_epoch):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        List\n",
        "    Return:\n",
        "        Number of parmaters, Number of Flops\n",
        "    '''\n",
        "    \n",
        "    # weight_list_per_epoch = my_get_weights_in_conv_layers(model,first_time)\n",
        "    l1_norms_filters_per_epoch = list()\n",
        "    \n",
        "\n",
        "    for index in range(len(weight_list_per_epoch)):\n",
        "\n",
        "        epochs = np.array(weight_list_per_epoch[index]).shape[0]\n",
        "        h , w , d = np.array(weight_list_per_epoch[index]).shape[1], np.array(weight_list_per_epoch[index]).shape[2] , np.array(weight_list_per_epoch[index]).shape[3]\n",
        "\n",
        "\n",
        "        l1_norms_filters_per_epoch.append(np.sum(np.abs(np.array(weight_list_per_epoch[index])).reshape(epochs,h*w*d,-1),axis=1))\n",
        "    return l1_norms_filters_per_epoch\n",
        "\n",
        "def my_in_conv_layers_get_sum_of_l1_norms_sorted_indices(weight_list_per_epoch):\n",
        "    '''\n",
        "        Arguments:\n",
        "            weight List \n",
        "        Return:\n",
        "            \n",
        "    '''\n",
        "    layer_wise_filter_sorted_indices = list()\n",
        "    layer_wise_filter_sorted_values = list()\n",
        "    l1_norms_filters_per_epoch = my_get_l1_norms_filters_per_epoch(weight_list_per_epoch)\n",
        "    sum_l1_norms = list()\n",
        "    \n",
        "    for i in l1_norms_filters_per_epoch:\n",
        "        sum_l1_norms.append(np.sum(i,axis=0))\n",
        "    \n",
        "    layer_wise_filter_sorted_indices = list()\n",
        "    \n",
        "    for i in sum_l1_norms:\n",
        "        a = pd.Series(i).sort_values().index\n",
        "        layer_wise_filter_sorted_indices.append(a.tolist())\n",
        "    return layer_wise_filter_sorted_indices\n",
        "\n",
        "\n",
        "def my_get_percent_prune_filter_indices(layer_wise_filter_sorted_indices,percentage):    \n",
        "\n",
        "    prune_filter_indices = list()\n",
        "    for i in range(len(layer_wise_filter_sorted_indices)):\n",
        "        prune_filter_indices.append(int(len(layer_wise_filter_sorted_indices[i]) * (percentage/100)))\n",
        "    return prune_filter_indices\n",
        "\n",
        "def my_get_distance_matrix(l1_norm_matrix):\n",
        "    distance_matrix = []\n",
        "    for i,v1 in enumerate(l1_norm_matrix):\n",
        "        distance_matrix.append([])\n",
        "        for v2 in l1_norm_matrix:\n",
        "            distance_matrix[i].append(np.sum(np.abs((v1-v2))))\n",
        "    return np.array(distance_matrix)\n",
        "    \n",
        "def my_get_distance_matrix_list(l1_norm_matrix_list):\n",
        "    distance_matrix_list = []\n",
        "    for l1_norm_matrix in l1_norm_matrix_list:\n",
        "        distance_matrix_list.append(my_get_distance_matrix(l1_norm_matrix.T))\n",
        "    return distance_matrix_list\n",
        "\n",
        "\n",
        "\n",
        "def my_get_episodes(distance_matrix,percentage):\n",
        "    distance_matrix_flatten = pd.Series(distance_matrix.flatten())\n",
        "    \n",
        "    distance_matrix_flatten = distance_matrix_flatten.sort_values().index.to_list()\n",
        "    \n",
        "    episodes = list()\n",
        "    n = distance_matrix.shape[0]\n",
        "    for i in distance_matrix_flatten:\n",
        "        episodes.append((i//n,i%n))\n",
        "    k = int((n * percentage)/100)\n",
        "    li = list()   \n",
        "    for i in range(2*k):\n",
        "        if i%2!=0:\n",
        "            li.append(episodes[n+i])\n",
        "    return li\n",
        "\n",
        "\n",
        "def my_get_episodes_for_all_layers(distance_matrix_list,percentage):\n",
        "    all_episodes = list()\n",
        "    for matrix in distance_matrix_list:\n",
        "        all_episodes.append(my_get_episodes(matrix,percentage))\n",
        "    return all_episodes\n",
        "\n",
        "\n",
        "def my_get_filter_pruning_indices(episodes_for_all_layers,l1_norm_matrix_list):\n",
        "    filter_pruning_indices = list()\n",
        "    for layer_index,episode_layer in enumerate(episodes_for_all_layers):\n",
        "        a = set()\n",
        "        sum_l1_norms = np.sum(l1_norm_matrix_list[layer_index],axis=0,keepdims=True)\n",
        "\n",
        "        for episode in episode_layer:\n",
        "            ep1 = sum_l1_norms.T[episode[0]]\n",
        "            ep2 = sum_l1_norms.T[episode[1]]\n",
        "            if ep1 >= ep2:\n",
        "                a.add(episode[0])\n",
        "            else:\n",
        "                a.add(episode[1])\n",
        "            a.add(episode[0])\n",
        "        a = list(a)\n",
        "        filter_pruning_indices.append(a)\n",
        "    return filter_pruning_indices\n",
        "\n",
        "\n",
        "    \n",
        "def my_delete_filters(model,weight_list_per_epoch,percentage,first_time,keep_prob):\n",
        "    l1_norms = my_get_l1_norms_filters_per_epoch(weight_list_per_epoch)\n",
        "    distance_matrix_list = my_get_distance_matrix_list(l1_norms)\n",
        "    episodes_for_all_layers = my_get_episodes_for_all_layers(distance_matrix_list,percentage)\n",
        "    filter_pruning_indices = my_get_filter_pruning_indices(episodes_for_all_layers,l1_norms)\n",
        "    all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "\n",
        "    surgeon = Surgeon(model)\n",
        "    for index,value in enumerate(all_conv_layers):\n",
        "        # print(index,value,filter_pruning_indices[index])\n",
        "        if np.random.rand(1) < keep_prob :\n",
        "            surgeon.add_job('delete_channels',model.layers[value],channels = filter_pruning_indices[index])\n",
        "    model_new = surgeon.operate()\n",
        "    return model_new    \n",
        "\n",
        "\n",
        "def count_conv_params_flops(conv_layer):\n",
        "    # out shape is  n_cells_dim1 * (n_cells_dim2 * n_cells_dim3)\n",
        "    '''\n",
        "    Arguments:\n",
        "        conv layer \n",
        "    Return:\n",
        "        Number of Parameters, Number of Flops\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    out_shape = conv_layer.output_shape\n",
        "\n",
        "    n_cells_total = np.prod(out_shape[1:-1])\n",
        "\n",
        "    n_conv_params_total = conv_layer.count_params()\n",
        "    # print(n_conv_params_total,len(conv_layer.get_weights()[0]),)\n",
        "    conv_flops = 2 * (n_conv_params_total * n_cells_total - len(conv_layer.get_weights()[1]) *n_cells_total)\n",
        "\n",
        " \n",
        "\n",
        "    return n_conv_params_total, conv_flops\n",
        "\n",
        "\n",
        "def count_dense_params_flops(dense_layer):\n",
        "    # out shape is  n_cells_dim1 * (n_cells_dim2 * n_cells_dim3)\n",
        "    '''\n",
        "    Arguments:\n",
        "      dense layer \n",
        "    Return:\n",
        "        Number of Parameters, Number of Flops\n",
        "    '''\n",
        "\n",
        "    out_shape = dense_layer.output_shape\n",
        "    n_cells_total = np.prod(out_shape[1:-1])\n",
        "\n",
        "    n_dense_params_total = dense_layer.count_params()\n",
        "\n",
        "    dense_flops = 2* (n_dense_params_total - len(dense_layer.get_weights()[1]) * n_cells_total)\n",
        "\n",
        "\n",
        "    return n_dense_params_total, dense_flops\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def count_model_params_flops(model,first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> boolean variable\n",
        "        first_time = True => model is not pruned \n",
        "        first_time = False => model is pruned\n",
        "    Return:\n",
        "        Number of parmaters, Number of Flops\n",
        "    '''\n",
        "\n",
        "    total_params = 0\n",
        "    total_flops = 0\n",
        "    # if first_time == True:\n",
        "    #     model_layers = model.layers[:-3]\n",
        "    # else:\n",
        "    #     model_layers = model.layers[1:-3]\n",
        "    model_layers = model.layers\n",
        "    for index,layer in enumerate(model_layers):\n",
        "        if any(conv_type in str(type(layer)) for conv_type in ['Conv1D', 'Conv2D', 'Conv3D']):\n",
        "            \n",
        "            params, flops = count_conv_params_flops(layer)\n",
        "            # print(index,layer.name,params,flops)\n",
        "            total_params += params\n",
        "            total_flops += flops\n",
        "        elif 'Dense' in str(type(layer)):\n",
        "            \n",
        "            params, flops = count_dense_params_flops(layer)\n",
        "            # print(index,layer.name,params,flops)\n",
        "            total_params += params\n",
        "            total_flops += flops\n",
        "    return total_params, int(total_flops)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMTzbZEz_aHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Get_Weights(Callback):\n",
        "    def __init__(self,first_time):\n",
        "        super(Get_Weights, self).__init__()\n",
        "        self.weight_list = [] #Using a list of list to store weight tensors per epoch\n",
        "        self.first_time = first_time\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        if epoch == 0:\n",
        "            all_conv_layers = my_get_all_conv_layers(self.model,self.first_time)\n",
        "            for i in range(len(all_conv_layers)):\n",
        "                self.weight_list.append([]) # appending empty lists for later appending weight tensors \n",
        "        \n",
        "        for index,each_weight in enumerate(my_get_weights_in_conv_layers(self.model,self.first_time)):\n",
        "                self.weight_list[index].append(each_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMOnJDNN_4Pn",
        "colab_type": "code",
        "outputId": "7f8002bd-dbf4-42c2-a4af-e91ae0b72d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=20, kernel_size=(5, 5), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=50, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=500, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "def train(model,epochs,first_time):\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "    img_rows, img_cols = 28, 28\n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "\n",
        "    gw = Get_Weights(first_time)\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=2,\n",
        "            callbacks=[gw],\n",
        "            validation_data=(x_test, y_test))\n",
        "\n",
        "    return model,history,gw.weight_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxJNveKnu8TZ",
        "colab_type": "code",
        "outputId": "8c1f3682-09ec-4065-ba53-ccb7c8e3c2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 20)        520       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 12, 12, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 50)          25050     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 4, 4, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               400500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 431,080\n",
            "Trainable params: 431,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bP_K7IRu4-X",
        "colab_type": "code",
        "outputId": "106f5220-a273-4d8a-e982-cae07f2e560f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "count_model_params_flops(model,True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(431080, 4586000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX-GWmZ-G0EY",
        "colab_type": "code",
        "outputId": "c1d39cc2-bba6-4b8b-9187-23501555447d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model,history,weight_list_per_epoch = train(model,10,True)\n",
        "initial_flops = count_model_params_flops(model,True)[1]\n",
        "log_dict = dict()\n",
        "log_dict['train_loss'] = []\n",
        "log_dict['train_acc'] = []\n",
        "log_dict['val_loss'] = []\n",
        "log_dict['val_acc'] = []\n",
        "log_dict['total_params'] = []\n",
        "log_dict['total_flops'] = []\n",
        "log_dict['filters_in_conv1'] = []\n",
        "log_dict['filters_in_conv2'] = []\n",
        "\n",
        "best_acc_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
        "log_dict['train_loss'].append(history.history['loss'][best_acc_index])\n",
        "log_dict['train_acc'].append(history.history['accuracy'][best_acc_index])\n",
        "log_dict['val_loss'].append(history.history['val_loss'][best_acc_index])\n",
        "log_dict['val_acc'].append(history.history['val_accuracy'][best_acc_index])\n",
        "a,b = count_model_params_flops(model,True)\n",
        "log_dict['total_params'].append(a)\n",
        "log_dict['total_flops'].append(b)\n",
        "log_dict['filters_in_conv1'].append(model.layers[0].get_weights()[0].shape[-1])\n",
        "log_dict['filters_in_conv2'].append(model.layers[2].get_weights()[0].shape[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.2306 - accuracy: 0.9303 - val_loss: 0.0623 - val_accuracy: 0.9806\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.0640 - accuracy: 0.9804 - val_loss: 0.0430 - val_accuracy: 0.9861\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0437 - accuracy: 0.9863 - val_loss: 0.0372 - val_accuracy: 0.9889\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0444 - val_accuracy: 0.9855\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.0352 - val_accuracy: 0.9892\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0284 - val_accuracy: 0.9908\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0289 - val_accuracy: 0.9896\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0309 - val_accuracy: 0.9899\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0293 - val_accuracy: 0.9922\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0257 - val_accuracy: 0.9925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1S03sauALXJ",
        "colab_type": "code",
        "outputId": "7579b5a5-bcdc-4b52-f589-d7e6fe72fefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Validation accuracy ',max(history.history['val_accuracy']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy  0.9925000071525574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSRZEO7CB0Bo",
        "colab_type": "code",
        "outputId": "61a75fdb-e3e8-4110-8db0-a330b5701cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#stop pruning if the accuracy drops by 5% from maximum accuracy ever obtained. \n",
        "validation_accuracy = max(history.history['val_accuracy'])\n",
        "print(\"Initial Validation Accuracy = {}\".format(validation_accuracy) )\n",
        "max_val_acc = validation_accuracy\n",
        "count = 0\n",
        "all_models = list()\n",
        "a,b = count_model_params_flops(model,False)\n",
        "print(a,b)\n",
        "while validation_accuracy - max_val_acc >= -0.01 and  count < 3:\n",
        "\n",
        "\n",
        "    print(\"ITERATION {} \".format(count+1))\n",
        "    all_models.append(model)\n",
        "    if max_val_acc < validation_accuracy:\n",
        "        max_val_acc = validation_accuracy\n",
        "        \n",
        "\n",
        "    if count < 1:\n",
        "        model = my_delete_filters(model,weight_list_per_epoch,50,True,1)\n",
        "        model,history,weight_list_per_epoch = train(model,10,False)\n",
        "   \n",
        "    else:\n",
        "        model = my_delete_filters(model,weight_list_per_epoch,20,False,1)\n",
        "        model,history,weight_list_per_epoch = train(model,30,False)\n",
        "    a,b = count_model_params_flops(model,False)\n",
        "    print(a,b)\n",
        "    \n",
        "\n",
        "    validation_accuracy = max(history.history['val_accuracy'])\n",
        "\n",
        "    best_acc_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
        "    log_dict['train_loss'].append(history.history['loss'][best_acc_index])\n",
        "    log_dict['train_acc'].append(history.history['accuracy'][best_acc_index])\n",
        "    log_dict['val_loss'].append(history.history['val_loss'][best_acc_index])\n",
        "    log_dict['val_acc'].append(history.history['val_accuracy'][best_acc_index])\n",
        "    a,b = count_model_params_flops(model,False)\n",
        "    log_dict['total_params'].append(a)\n",
        "    log_dict['total_flops'].append(b)\n",
        "    log_dict['filters_in_conv1'].append(model.layers[1].get_weights()[0].shape[-1])\n",
        "    log_dict['filters_in_conv2'].append(model.layers[3].get_weights()[0].shape[-1])\n",
        "    print(\"VALIDATION ACCURACY AFTER {} ITERATIONS = {}\".format(count+1,validation_accuracy))\n",
        "    count+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Validation Accuracy = 0.9925000071525574\n",
            "431080 4586000\n",
            "ITERATION 1 \n",
            "Deleting 10/20 channels from layer: conv2d_1\n",
            "Deleting 24/50 channels from layer: conv2d_2\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.0199 - accuracy: 0.9935 - val_loss: 0.0251 - val_accuracy: 0.9914\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.0278 - val_accuracy: 0.9910\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0259 - val_accuracy: 0.9922\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0306 - val_accuracy: 0.9907\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.9912\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0327 - val_accuracy: 0.9910\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0407 - val_accuracy: 0.9891\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0339 - val_accuracy: 0.9909\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0386 - val_accuracy: 0.9918\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0375 - val_accuracy: 0.9907\n",
            "220296 1546000\n",
            "VALIDATION ACCURACY AFTER 1 ITERATIONS = 0.9922000169754028\n",
            "ITERATION 2 \n",
            "Deleting 3/10 channels from layer: conv2d_1\n",
            "Deleting 9/26 channels from layer: conv2d_2\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            " - 2s - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0314 - val_accuracy: 0.9908\n",
            "Epoch 2/30\n",
            " - 2s - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0298 - val_accuracy: 0.9903\n",
            "Epoch 3/30\n",
            " - 2s - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0349 - val_accuracy: 0.9901\n",
            "Epoch 4/30\n",
            " - 2s - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0375 - val_accuracy: 0.9896\n",
            "Epoch 5/30\n",
            " - 2s - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0333 - val_accuracy: 0.9916\n",
            "Epoch 6/30\n",
            " - 2s - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0331 - val_accuracy: 0.9909\n",
            "Epoch 7/30\n",
            " - 2s - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0424 - val_accuracy: 0.9896\n",
            "Epoch 8/30\n",
            " - 2s - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0370 - val_accuracy: 0.9907\n",
            "Epoch 9/30\n",
            " - 2s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0383 - val_accuracy: 0.9911\n",
            "Epoch 10/30\n",
            " - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0474 - val_accuracy: 0.9901\n",
            "Epoch 11/30\n",
            " - 2s - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0478 - val_accuracy: 0.9900\n",
            "Epoch 12/30\n",
            " - 2s - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0363 - val_accuracy: 0.9917\n",
            "Epoch 13/30\n",
            " - 2s - loss: 6.6499e-04 - accuracy: 0.9998 - val_loss: 0.0470 - val_accuracy: 0.9910\n",
            "Epoch 14/30\n",
            " - 2s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0449 - val_accuracy: 0.9911\n",
            "Epoch 15/30\n",
            " - 2s - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0511 - val_accuracy: 0.9896\n",
            "Epoch 16/30\n",
            " - 2s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0403 - val_accuracy: 0.9898\n",
            "Epoch 17/30\n",
            " - 2s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0430 - val_accuracy: 0.9910\n",
            "Epoch 18/30\n",
            " - 2s - loss: 6.4786e-04 - accuracy: 0.9998 - val_loss: 0.0536 - val_accuracy: 0.9907\n",
            "Epoch 19/30\n",
            " - 2s - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0430 - val_accuracy: 0.9910\n",
            "Epoch 20/30\n",
            " - 2s - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0407 - val_accuracy: 0.9908\n",
            "Epoch 21/30\n",
            " - 2s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0366 - val_accuracy: 0.9912\n",
            "Epoch 22/30\n",
            " - 2s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0356 - val_accuracy: 0.9916\n",
            "Epoch 23/30\n",
            " - 2s - loss: 3.7496e-04 - accuracy: 0.9999 - val_loss: 0.0369 - val_accuracy: 0.9913\n",
            "Epoch 24/30\n",
            " - 2s - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0417 - val_accuracy: 0.9907\n",
            "Epoch 25/30\n",
            " - 2s - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0447 - val_accuracy: 0.9908\n",
            "Epoch 26/30\n",
            " - 2s - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0462 - val_accuracy: 0.9907\n",
            "Epoch 27/30\n",
            " - 2s - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0399 - val_accuracy: 0.9920\n",
            "Epoch 28/30\n",
            " - 2s - loss: 1.3444e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9908\n",
            "Epoch 29/30\n",
            " - 2s - loss: 1.0361e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9920\n",
            "Epoch 30/30\n",
            " - 2s - loss: 2.9205e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9920\n",
            "144684 864400\n",
            "VALIDATION ACCURACY AFTER 2 ITERATIONS = 0.9919999837875366\n",
            "ITERATION 3 \n",
            "Deleting 1/7 channels from layer: conv2d_1\n",
            "Deleting 4/17 channels from layer: conv2d_2\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            " - 2s - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.0390 - val_accuracy: 0.9898\n",
            "Epoch 2/30\n",
            " - 2s - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0362 - val_accuracy: 0.9909\n",
            "Epoch 3/30\n",
            " - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0394 - val_accuracy: 0.9909\n",
            "Epoch 4/30\n",
            " - 2s - loss: 6.3121e-04 - accuracy: 0.9999 - val_loss: 0.0395 - val_accuracy: 0.9912\n",
            "Epoch 5/30\n",
            " - 2s - loss: 7.6506e-04 - accuracy: 0.9998 - val_loss: 0.0406 - val_accuracy: 0.9909\n",
            "Epoch 6/30\n",
            " - 2s - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0395 - val_accuracy: 0.9907\n",
            "Epoch 7/30\n",
            " - 2s - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0432 - val_accuracy: 0.9903\n",
            "Epoch 8/30\n",
            " - 2s - loss: 5.7436e-04 - accuracy: 0.9998 - val_loss: 0.0433 - val_accuracy: 0.9916\n",
            "Epoch 9/30\n",
            " - 2s - loss: 1.0491e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9918\n",
            "Epoch 10/30\n",
            " - 2s - loss: 5.7487e-05 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9918\n",
            "Epoch 11/30\n",
            " - 2s - loss: 3.7806e-05 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9920\n",
            "Epoch 12/30\n",
            " - 2s - loss: 2.9926e-05 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9920\n",
            "Epoch 13/30\n",
            " - 2s - loss: 2.3514e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9918\n",
            "Epoch 14/30\n",
            " - 2s - loss: 1.8297e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9921\n",
            "Epoch 15/30\n",
            " - 2s - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0495 - val_accuracy: 0.9895\n",
            "Epoch 16/30\n",
            " - 2s - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0475 - val_accuracy: 0.9897\n",
            "Epoch 17/30\n",
            " - 2s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0401 - val_accuracy: 0.9919\n",
            "Epoch 18/30\n",
            " - 2s - loss: 2.0022e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9918\n",
            "Epoch 19/30\n",
            " - 2s - loss: 6.0528e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9913\n",
            "Epoch 20/30\n",
            " - 2s - loss: 2.9790e-05 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9911\n",
            "Epoch 21/30\n",
            " - 2s - loss: 2.2352e-05 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9913\n",
            "Epoch 22/30\n",
            " - 2s - loss: 1.7525e-05 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9913\n",
            "Epoch 23/30\n",
            " - 2s - loss: 1.4301e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9913\n",
            "Epoch 24/30\n",
            " - 2s - loss: 1.0981e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9917\n",
            "Epoch 25/30\n",
            " - 2s - loss: 8.6357e-06 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9916\n",
            "Epoch 26/30\n",
            " - 2s - loss: 7.3883e-06 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9917\n",
            "Epoch 27/30\n",
            " - 2s - loss: 5.4706e-06 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9916\n",
            "Epoch 28/30\n",
            " - 2s - loss: 4.3792e-06 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9918\n",
            "Epoch 29/30\n",
            " - 2s - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0454 - val_accuracy: 0.9911\n",
            "Epoch 30/30\n",
            " - 2s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0477 - val_accuracy: 0.9913\n",
            "111629 640400\n",
            "VALIDATION ACCURACY AFTER 3 ITERATIONS = 0.9921000003814697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcJvyh0U60Vu",
        "colab_type": "code",
        "outputId": "88c3379f-651d-4ddb-d969-43ec8c9552f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 13)          1963      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               104500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 111,629\n",
            "Trainable params: 111,629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6-J_KDz2kM1",
        "colab_type": "code",
        "outputId": "307be852-c22d-417b-a55b-e7b0373630e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "l1_norms = my_get_l1_norms_filters_per_epoch(weight_list_per_epoch)\n",
        "distance_matrix_list = my_get_distance_matrix_list(l1_norms)\n",
        "episodes_for_all_layers = my_get_episodes_for_all_layers(distance_matrix_list,95)\n",
        "filter_pruning_indices = my_get_filter_pruning_indices(episodes_for_all_layers,l1_norms)\n",
        "print(filter_pruning_indices[0][:1],filter_pruning_indices[1][:6])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] [0, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsfAYrKj2x2O",
        "colab_type": "code",
        "outputId": "dc0e1c5c-21c0-4d9b-b296-20f4f183b82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "\n",
        "surgeon = Surgeon(model)\n",
        "surgeon.add_job('delete_channels',model.layers[1],channels = filter_pruning_indices[0][:1])\n",
        "surgeon.add_job('delete_channels',model.layers[3],channels =filter_pruning_indices[1][:1])\n",
        "model = surgeon.operate()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting 1/3 channels from layer: conv2d_1\n",
            "Deleting 1/4 channels from layer: conv2d_2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug3JpdQ_mL7B",
        "colab_type": "code",
        "outputId": "6f294e26-26f9-4fd0-bac3-48b9b3c9ab97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 2)         52        \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 3)           153       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               24500     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 29,715\n",
            "Trainable params: 29,715\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1TsjomcaPLD",
        "colab_type": "code",
        "outputId": "3cd2b18b-810a-466d-c967-168509bfa1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model,history,weight_list_per_epoch = train(model,60,False)\n",
        "\n",
        "best_acc_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
        "log_dict['train_loss'].append(history.history['loss'][best_acc_index])\n",
        "log_dict['train_acc'].append(history.history['accuracy'][best_acc_index])\n",
        "log_dict['val_loss'].append(history.history['val_loss'][best_acc_index])\n",
        "log_dict['val_acc'].append(history.history['val_accuracy'][best_acc_index])\n",
        "a,b = count_model_params_flops(model,False)\n",
        "log_dict['total_params'].append(a)\n",
        "log_dict['total_flops'].append(b)\n",
        "log_dict['filters_in_conv1'].append(model.layers[1].get_weights()[0].shape[-1])\n",
        "log_dict['filters_in_conv2'].append(model.layers[3].get_weights()[0].shape[-1])\n",
        "print(\"Final Validation Accuracy = \",(max(history.history['val_accuracy'])*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/60\n",
            " - 2s - loss: 0.2040 - accuracy: 0.9556 - val_loss: 0.1052 - val_accuracy: 0.9733\n",
            "Epoch 2/60\n",
            " - 2s - loss: 0.0588 - accuracy: 0.9813 - val_loss: 0.0824 - val_accuracy: 0.9786\n",
            "Epoch 3/60\n",
            " - 2s - loss: 0.0402 - accuracy: 0.9866 - val_loss: 0.0795 - val_accuracy: 0.9792\n",
            "Epoch 4/60\n",
            " - 2s - loss: 0.0310 - accuracy: 0.9894 - val_loss: 0.0719 - val_accuracy: 0.9803\n",
            "Epoch 5/60\n",
            " - 2s - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0696 - val_accuracy: 0.9814\n",
            "Epoch 6/60\n",
            " - 2s - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0710 - val_accuracy: 0.9827\n",
            "Epoch 7/60\n",
            " - 2s - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0696 - val_accuracy: 0.9829\n",
            "Epoch 8/60\n",
            " - 2s - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0745 - val_accuracy: 0.9831\n",
            "Epoch 9/60\n",
            " - 2s - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0734 - val_accuracy: 0.9834\n",
            "Epoch 10/60\n",
            " - 2s - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.0808 - val_accuracy: 0.9831\n",
            "Epoch 11/60\n",
            " - 2s - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0796 - val_accuracy: 0.9827\n",
            "Epoch 12/60\n",
            " - 2s - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.0821 - val_accuracy: 0.9842\n",
            "Epoch 13/60\n",
            " - 2s - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0898 - val_accuracy: 0.9825\n",
            "Epoch 14/60\n",
            " - 2s - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0827 - val_accuracy: 0.9843\n",
            "Epoch 15/60\n",
            " - 2s - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0867 - val_accuracy: 0.9836\n",
            "Epoch 16/60\n",
            " - 2s - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0854 - val_accuracy: 0.9845\n",
            "Epoch 17/60\n",
            " - 2s - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0859 - val_accuracy: 0.9843\n",
            "Epoch 18/60\n",
            " - 2s - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0988 - val_accuracy: 0.9826\n",
            "Epoch 19/60\n",
            " - 2s - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0936 - val_accuracy: 0.9829\n",
            "Epoch 20/60\n",
            " - 2s - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0924 - val_accuracy: 0.9843\n",
            "Epoch 21/60\n",
            " - 2s - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0895 - val_accuracy: 0.9844\n",
            "Epoch 22/60\n",
            " - 2s - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0890 - val_accuracy: 0.9851\n",
            "Epoch 23/60\n",
            " - 2s - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1018 - val_accuracy: 0.9831\n",
            "Epoch 24/60\n",
            " - 2s - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0937 - val_accuracy: 0.9858\n",
            "Epoch 25/60\n",
            " - 2s - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0951 - val_accuracy: 0.9840\n",
            "Epoch 26/60\n",
            " - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1005 - val_accuracy: 0.9838\n",
            "Epoch 27/60\n",
            " - 2s - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1084 - val_accuracy: 0.9832\n",
            "Epoch 28/60\n",
            " - 2s - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.1048 - val_accuracy: 0.9832\n",
            "Epoch 29/60\n",
            " - 2s - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0965 - val_accuracy: 0.9843\n",
            "Epoch 30/60\n",
            " - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1028 - val_accuracy: 0.9844\n",
            "Epoch 31/60\n",
            " - 2s - loss: 4.8046e-04 - accuracy: 0.9999 - val_loss: 0.1002 - val_accuracy: 0.9849\n",
            "Epoch 32/60\n",
            " - 2s - loss: 3.6035e-04 - accuracy: 0.9999 - val_loss: 0.1008 - val_accuracy: 0.9848\n",
            "Epoch 33/60\n",
            " - 2s - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1220 - val_accuracy: 0.9822\n",
            "Epoch 34/60\n",
            " - 2s - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1011 - val_accuracy: 0.9835\n",
            "Epoch 35/60\n",
            " - 2s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0996 - val_accuracy: 0.9838\n",
            "Epoch 36/60\n",
            " - 2s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1066 - val_accuracy: 0.9824\n",
            "Epoch 37/60\n",
            " - 2s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1079 - val_accuracy: 0.9834\n",
            "Epoch 38/60\n",
            " - 2s - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1100 - val_accuracy: 0.9843\n",
            "Epoch 39/60\n",
            " - 2s - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1109 - val_accuracy: 0.9817\n",
            "Epoch 40/60\n",
            " - 2s - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.1071 - val_accuracy: 0.9831\n",
            "Epoch 41/60\n",
            " - 2s - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1021 - val_accuracy: 0.9842\n",
            "Epoch 42/60\n",
            " - 2s - loss: 6.2256e-04 - accuracy: 0.9998 - val_loss: 0.1009 - val_accuracy: 0.9855\n",
            "Epoch 43/60\n",
            " - 2s - loss: 1.2802e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9855\n",
            "Epoch 44/60\n",
            " - 2s - loss: 8.3008e-05 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9859\n",
            "Epoch 45/60\n",
            " - 2s - loss: 6.7140e-05 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9858\n",
            "Epoch 46/60\n",
            " - 2s - loss: 5.5492e-05 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9855\n",
            "Epoch 47/60\n",
            " - 2s - loss: 4.6751e-05 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9859\n",
            "Epoch 48/60\n",
            " - 2s - loss: 4.2196e-05 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9860\n",
            "Epoch 49/60\n",
            " - 2s - loss: 3.5895e-05 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9855\n",
            "Epoch 50/60\n",
            " - 2s - loss: 3.1637e-05 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9858\n",
            "Epoch 51/60\n",
            " - 2s - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.1605 - val_accuracy: 0.9777\n",
            "Epoch 52/60\n",
            " - 2s - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.1092 - val_accuracy: 0.9837\n",
            "Epoch 53/60\n",
            " - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0999 - val_accuracy: 0.9842\n",
            "Epoch 54/60\n",
            " - 2s - loss: 4.1222e-04 - accuracy: 0.9999 - val_loss: 0.1010 - val_accuracy: 0.9851\n",
            "Epoch 55/60\n",
            " - 2s - loss: 1.1730e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9854\n",
            "Epoch 56/60\n",
            " - 2s - loss: 8.4852e-05 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9855\n",
            "Epoch 57/60\n",
            " - 2s - loss: 6.8703e-05 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9856\n",
            "Epoch 58/60\n",
            " - 2s - loss: 5.6855e-05 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9860\n",
            "Epoch 59/60\n",
            " - 2s - loss: 4.7654e-05 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9861\n",
            "Epoch 60/60\n",
            " - 2s - loss: 4.0533e-05 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9859\n",
            "Final Validation Accuracy =  98.61000180244446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6x5C1eFBSXJ",
        "colab_type": "code",
        "outputId": "4019d549-ade4-41d3-8d61-6c2dabbec7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_flops = count_model_params_flops(model,False)[1]\n",
        "print(\"Total reduction in Flops in Conv layers = {}%\".format(((initial_flops-final_flops)/initial_flops)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total reduction in Flops in Conv layers = 97.06061927605757%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES_-ddmzEklQ",
        "colab_type": "code",
        "outputId": "f552dbc1-447d-4af8-a69e-9e341f2d7bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 2)         52        \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 3)           153       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               24500     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 29,715\n",
            "Trainable params: 29,715\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV8-KNDCB3sJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_df = pd.DataFrame(log_dict)\n",
        "log_df.to_csv('/content/drive/My Drive/RR5.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "730rifL3iP1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}