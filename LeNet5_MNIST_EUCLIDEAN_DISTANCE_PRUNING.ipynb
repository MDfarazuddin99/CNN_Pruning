{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet5_MNIST_EUCLIDEAN_DISTANCE_PRUNING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDfarazuddin99/CNN_Pruning/blob/master/LeNet5_MNIST_EUCLIDEAN_DISTANCE_PRUNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiuqUfkbutTN",
        "colab_type": "code",
        "outputId": "45867b10-7997-4848-f8bc-56312ac2714a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAvZwpu-9IP",
        "colab_type": "code",
        "outputId": "f79b59d9-388c-4f70-b1f8-33913246572b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "# !pip install tesnsorflow 1.x\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D,BatchNormalization,Activation,AveragePooling2D\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "!pip install kerassurgeon\n",
        "from kerassurgeon import identify \n",
        "from kerassurgeon.operations import delete_channels,delete_layer\n",
        "from kerassurgeon import Surgeon"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kerassurgeon in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from kerassurgeon) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.18.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz5XrgH0_Xod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_get_all_conv_layers(model , first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> type boolean \n",
        "            first_time = True => model is not pruned \n",
        "            first_time = False => model is pruned\n",
        "    Return:\n",
        "        List of Indices containing convolution layers\n",
        "    '''\n",
        "\n",
        "    all_conv_layers = list()\n",
        "    for i,each_layer in enumerate(model.layers):\n",
        "        if (each_layer.name[0:6] == 'conv2d'):\n",
        "            all_conv_layers.append(i)\n",
        "    return all_conv_layers if (first_time==True) else all_conv_layers[1:]\n",
        "\n",
        "\n",
        "def my_get_all_dense_layers(model):\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model        \n",
        "    Return:\n",
        "        List of Indices containing fully connected layers\n",
        "    '''\n",
        "    all_dense_layers = list()\n",
        "    for i,each_layer in enumerate(model.layers):\n",
        "        if (each_layer.name[0:5] == 'dense'):\n",
        "            all_dense_layers.append(i)\n",
        "    return all_dense_layers\n",
        "\n",
        "\n",
        "\n",
        "def my_get_weights_in_conv_layers(model,first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> boolean variable\n",
        "            first_time = True => model is not pruned \n",
        "            first_time = False => model is pruned\n",
        "    Return:\n",
        "        List containing weight tensors of each layer\n",
        "    '''\n",
        "    weights = list()\n",
        "    all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "    layer_wise_weights = list() \n",
        "    for i in all_conv_layers:\n",
        "          weights.append(model.layers[i].get_weights()[0])  \n",
        "    return weights\n",
        "\n",
        "def my_get_l1_norms_filters_per_epoch(weight_list_per_epoch):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        List\n",
        "    Return:\n",
        "        Number of parmaters, Number of Flops\n",
        "    '''\n",
        "    \n",
        "    # weight_list_per_epoch = my_get_weights_in_conv_layers(model,first_time)\n",
        "    l1_norms_filters_per_epoch = list()\n",
        "    \n",
        "\n",
        "    for index in range(len(weight_list_per_epoch)):\n",
        "\n",
        "        epochs = np.array(weight_list_per_epoch[index]).shape[0]\n",
        "        h , w , d = np.array(weight_list_per_epoch[index]).shape[1], np.array(weight_list_per_epoch[index]).shape[2] , np.array(weight_list_per_epoch[index]).shape[3]\n",
        "\n",
        "\n",
        "        l1_norms_filters_per_epoch.append(np.sum(np.abs(np.array(weight_list_per_epoch[index])).reshape(epochs,h*w*d,-1),axis=1))\n",
        "    return l1_norms_filters_per_epoch\n",
        "\n",
        "def my_in_conv_layers_get_sum_of_l1_norms_sorted_indices(weight_list_per_epoch):\n",
        "    '''\n",
        "        Arguments:\n",
        "            weight List \n",
        "        Return:\n",
        "            \n",
        "    '''\n",
        "    layer_wise_filter_sorted_indices = list()\n",
        "    layer_wise_filter_sorted_values = list()\n",
        "    l1_norms_filters_per_epoch = my_get_l1_norms_filters_per_epoch(weight_list_per_epoch)\n",
        "    sum_l1_norms = list()\n",
        "    \n",
        "    for i in l1_norms_filters_per_epoch:\n",
        "        sum_l1_norms.append(np.sum(i,axis=0))\n",
        "    \n",
        "    layer_wise_filter_sorted_indices = list()\n",
        "    \n",
        "    for i in sum_l1_norms:\n",
        "        a = pd.Series(i).sort_values().index\n",
        "        layer_wise_filter_sorted_indices.append(a.tolist())\n",
        "    return layer_wise_filter_sorted_indices\n",
        "\n",
        "\n",
        "def my_get_percent_prune_filter_indices(layer_wise_filter_sorted_indices,percentage):    \n",
        "\n",
        "    prune_filter_indices = list()\n",
        "    for i in range(len(layer_wise_filter_sorted_indices)):\n",
        "        prune_filter_indices.append(int(len(layer_wise_filter_sorted_indices[i]) * (percentage/100)))\n",
        "    return prune_filter_indices\n",
        "\n",
        "def my_get_distance_matrix(l1_norm_matrix):\n",
        "    distance_matrix = []\n",
        "    for i,v1 in enumerate(l1_norm_matrix):\n",
        "        distance_matrix.append([])\n",
        "        for v2 in l1_norm_matrix:\n",
        "            distance_matrix[i].append(np.sum(np.abs((v1-v2))))\n",
        "    return np.array(distance_matrix)\n",
        "    \n",
        "def my_get_distance_matrix_list(l1_norm_matrix_list):\n",
        "    distance_matrix_list = []\n",
        "    for l1_norm_matrix in l1_norm_matrix_list:\n",
        "        distance_matrix_list.append(my_get_distance_matrix(l1_norm_matrix.T))\n",
        "    return distance_matrix_list\n",
        "\n",
        "\n",
        "\n",
        "def my_get_episodes(distance_matrix,percentage):\n",
        "    distance_matrix_flatten = pd.Series(distance_matrix.flatten())\n",
        "    \n",
        "    distance_matrix_flatten = distance_matrix_flatten.sort_values().index.to_list()\n",
        "    \n",
        "    episodes = list()\n",
        "    n = distance_matrix.shape[0]\n",
        "    for i in distance_matrix_flatten:\n",
        "        episodes.append((i//n,i%n))\n",
        "    k = int((n * percentage)/100)\n",
        "    li = list()   \n",
        "    for i in range(2*k):\n",
        "        if i%2!=0:\n",
        "            li.append(episodes[n+i])\n",
        "    return li\n",
        "\n",
        "\n",
        "def my_get_episodes_for_all_layers(distance_matrix_list,percentage):\n",
        "    all_episodes = list()\n",
        "    for matrix in distance_matrix_list:\n",
        "        all_episodes.append(my_get_episodes(matrix,percentage))\n",
        "    return all_episodes\n",
        "\n",
        "\n",
        "def my_get_filter_pruning_indices(episodes_for_all_layers,l1_norm_matrix_list):\n",
        "    filter_pruning_indices = list()\n",
        "    for layer_index,episode_layer in enumerate(episodes_for_all_layers):\n",
        "        a = set()\n",
        "        sum_l1_norms = np.sum(l1_norm_matrix_list[layer_index],axis=0,keepdims=True)\n",
        "\n",
        "        for episode in episode_layer:\n",
        "            ep1 = sum_l1_norms.T[episode[0]]\n",
        "            ep2 = sum_l1_norms.T[episode[1]]\n",
        "            if ep1 >= ep2:\n",
        "                a.add(episode[0])\n",
        "            else:\n",
        "                a.add(episode[1])\n",
        "            a.add(episode[0])\n",
        "        a = list(a)\n",
        "        filter_pruning_indices.append(a)\n",
        "    return filter_pruning_indices\n",
        "\n",
        "\n",
        "    \n",
        "def my_delete_filters(model,weight_list_per_epoch,percentage,first_time,keep_prob):\n",
        "    l1_norms = my_get_l1_norms_filters_per_epoch(weight_list_per_epoch)\n",
        "    distance_matrix_list = my_get_distance_matrix_list(l1_norms)\n",
        "    episodes_for_all_layers = my_get_episodes_for_all_layers(distance_matrix_list,percentage)\n",
        "    filter_pruning_indices = my_get_filter_pruning_indices(episodes_for_all_layers,l1_norms)\n",
        "    all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "\n",
        "    surgeon = Surgeon(model)\n",
        "    for index,value in enumerate(all_conv_layers):\n",
        "        # print(index,value,filter_pruning_indices[index])\n",
        "        if np.random.rand(1) < keep_prob :\n",
        "            surgeon.add_job('delete_channels',model.layers[value],channels = filter_pruning_indices[index])\n",
        "    model_new = surgeon.operate()\n",
        "    return model_new    \n",
        "\n",
        "\n",
        "def count_conv_params_flops(conv_layer):\n",
        "    # out shape is  n_cells_dim1 * (n_cells_dim2 * n_cells_dim3)\n",
        "    '''\n",
        "    Arguments:\n",
        "        conv layer \n",
        "    Return:\n",
        "        Number of Parameters, Number of Flops\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    out_shape = conv_layer.output_shape\n",
        "\n",
        "    n_cells_total = np.prod(out_shape[1:-1])\n",
        "\n",
        "    n_conv_params_total = conv_layer.count_params()\n",
        "    # print(n_conv_params_total,len(conv_layer.get_weights()[0]),)\n",
        "    conv_flops = 2 * (n_conv_params_total * n_cells_total - len(conv_layer.get_weights()[1]) *n_cells_total)\n",
        "\n",
        " \n",
        "\n",
        "    return n_conv_params_total, conv_flops\n",
        "\n",
        "\n",
        "def count_dense_params_flops(dense_layer):\n",
        "    # out shape is  n_cells_dim1 * (n_cells_dim2 * n_cells_dim3)\n",
        "    '''\n",
        "    Arguments:\n",
        "      dense layer \n",
        "    Return:\n",
        "        Number of Parameters, Number of Flops\n",
        "    '''\n",
        "\n",
        "    out_shape = dense_layer.output_shape\n",
        "    n_cells_total = np.prod(out_shape[1:-1])\n",
        "\n",
        "    n_dense_params_total = dense_layer.count_params()\n",
        "\n",
        "    dense_flops = 2* (n_dense_params_total - len(dense_layer.get_weights()[1]) * n_cells_total)\n",
        "\n",
        "\n",
        "    return n_dense_params_total, dense_flops\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def count_model_params_flops(model,first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> boolean variable\n",
        "        first_time = True => model is not pruned \n",
        "        first_time = False => model is pruned\n",
        "    Return:\n",
        "        Number of parmaters, Number of Flops\n",
        "    '''\n",
        "\n",
        "    total_params = 0\n",
        "    total_flops = 0\n",
        "    # if first_time == True:\n",
        "    #     model_layers = model.layers[:-3]\n",
        "    # else:\n",
        "    #     model_layers = model.layers[1:-3]\n",
        "    model_layers = model.layers\n",
        "    for index,layer in enumerate(model_layers):\n",
        "        if any(conv_type in str(type(layer)) for conv_type in ['Conv1D', 'Conv2D', 'Conv3D']):\n",
        "            \n",
        "            params, flops = count_conv_params_flops(layer)\n",
        "            # print(index,layer.name,params,flops)\n",
        "            total_params += params\n",
        "            total_flops += flops\n",
        "        elif 'Dense' in str(type(layer)):\n",
        "            \n",
        "            params, flops = count_dense_params_flops(layer)\n",
        "            # print(index,layer.name,params,flops)\n",
        "            total_params += params\n",
        "            total_flops += flops\n",
        "    return total_params, int(total_flops)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMTzbZEz_aHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Get_Weights(Callback):\n",
        "    def __init__(self,first_time):\n",
        "        super(Get_Weights, self).__init__()\n",
        "        self.weight_list = [] #Using a list of list to store weight tensors per epoch\n",
        "        self.first_time = first_time\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        if epoch == 0:\n",
        "            all_conv_layers = my_get_all_conv_layers(self.model,self.first_time)\n",
        "            for i in range(len(all_conv_layers)):\n",
        "                self.weight_list.append([]) # appending empty lists for later appending weight tensors \n",
        "        \n",
        "        for index,each_weight in enumerate(my_get_weights_in_conv_layers(self.model,self.first_time)):\n",
        "                self.weight_list[index].append(each_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMOnJDNN_4Pn",
        "colab_type": "code",
        "outputId": "9d94e664-c3f4-43d7-9b8d-26399fdc6620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=20, kernel_size=(5, 5), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=50, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=500, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "def train(model,epochs,first_time):\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "    img_rows, img_cols = 28, 28\n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "\n",
        "    gw = Get_Weights(first_time)\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=2,\n",
        "            callbacks=[gw],\n",
        "            validation_data=(x_test, y_test))\n",
        "\n",
        "    return model,history,gw.weight_list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxJNveKnu8TZ",
        "colab_type": "code",
        "outputId": "28a7ab84-7d1b-415d-8e22-41247a8af3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 50)          25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               400500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 431,080\n",
            "Trainable params: 431,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bP_K7IRu4-X",
        "colab_type": "code",
        "outputId": "21bbb6da-b82f-4c5b-c1a2-d6f5f60264ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "count_model_params_flops(model,True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(431080, 4586000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX-GWmZ-G0EY",
        "colab_type": "code",
        "outputId": "038a13a0-43eb-4859-9ab2-46c7fb5bb4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "source": [
        "model,history,weight_list_per_epoch = train(model,10,True)\n",
        "initial_flops = count_model_params_flops(model,True)[1]\n",
        "log_dict = dict()\n",
        "log_dict['train_loss'] = []\n",
        "log_dict['train_acc'] = []\n",
        "log_dict['val_loss'] = []\n",
        "log_dict['val_acc'] = []\n",
        "log_dict['total_params'] = []\n",
        "log_dict['total_flops'] = []\n",
        "log_dict['filters_in_conv1'] = []\n",
        "log_dict['filters_in_conv2'] = []\n",
        "\n",
        "best_acc_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
        "log_dict['train_loss'].append(history.history['loss'][best_acc_index])\n",
        "log_dict['train_acc'].append(history.history['accuracy'][best_acc_index])\n",
        "log_dict['val_loss'].append(history.history['val_loss'][best_acc_index])\n",
        "log_dict['val_acc'].append(history.history['val_accuracy'][best_acc_index])\n",
        "a,b = count_model_params_flops(model,True)\n",
        "log_dict['total_params'].append(a)\n",
        "log_dict['total_flops'].append(b)\n",
        "log_dict['filters_in_conv1'].append(model.layers[0].get_weights()[0].shape[-1])\n",
        "log_dict['filters_in_conv2'].append(model.layers[2].get_weights()[0].shape[-1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.1810 - accuracy: 0.9442 - val_loss: 0.0481 - val_accuracy: 0.9847\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.0389 - val_accuracy: 0.9874\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0325 - val_accuracy: 0.9893\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0258 - accuracy: 0.9918 - val_loss: 0.0272 - val_accuracy: 0.9903\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0289 - val_accuracy: 0.9905\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0250 - val_accuracy: 0.9920\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0335 - val_accuracy: 0.9901\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0258 - val_accuracy: 0.9927\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0390 - val_accuracy: 0.9888\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0393 - val_accuracy: 0.9899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1S03sauALXJ",
        "colab_type": "code",
        "outputId": "87a6396f-78ca-4030-cd52-928d91423710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Validation accuracy ',max(history.history['val_accuracy']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy  0.9926999807357788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSRZEO7CB0Bo",
        "colab_type": "code",
        "outputId": "0c1c693e-deb3-4b21-e8e7-b9049f1ce52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#stop pruning if the accuracy drops by 5% from maximum accuracy ever obtained. \n",
        "validation_accuracy = max(history.history['val_accuracy'])\n",
        "print(\"Initial Validation Accuracy = {}\".format(validation_accuracy) )\n",
        "max_val_acc = validation_accuracy\n",
        "count = 0\n",
        "all_models = list()\n",
        "a,b = count_model_params_flops(model,False)\n",
        "print(a,b)\n",
        "while validation_accuracy - max_val_acc >= -0.01 and  count < 3:\n",
        "\n",
        "\n",
        "    print(\"ITERATION {} \".format(count+1))\n",
        "    all_models.append(model)\n",
        "    if max_val_acc < validation_accuracy:\n",
        "        max_val_acc = validation_accuracy\n",
        "        \n",
        "\n",
        "    if count < 1:\n",
        "        model = my_delete_filters(model,weight_list_per_epoch,50,True,1)\n",
        "        model,history,weight_list_per_epoch = train(model,10,False)\n",
        "   \n",
        "    else:\n",
        "        model = my_delete_filters(model,weight_list_per_epoch,20,False,1)\n",
        "        model,history,weight_list_per_epoch = train(model,30,False)\n",
        "    a,b = count_model_params_flops(model,False)\n",
        "    print(a,b)\n",
        "    \n",
        "\n",
        "    validation_accuracy = max(history.history['val_accuracy'])\n",
        "\n",
        "    best_acc_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
        "    log_dict['train_loss'].append(history.history['loss'][best_acc_index])\n",
        "    log_dict['train_acc'].append(history.history['accuracy'][best_acc_index])\n",
        "    log_dict['val_loss'].append(history.history['val_loss'][best_acc_index])\n",
        "    log_dict['val_acc'].append(history.history['val_accuracy'][best_acc_index])\n",
        "    a,b = count_model_params_flops(model,False)\n",
        "    log_dict['total_params'].append(a)\n",
        "    log_dict['total_flops'].append(b)\n",
        "    log_dict['filters_in_conv1'].append(model.layers[1].get_weights()[0].shape[-1])\n",
        "    log_dict['filters_in_conv2'].append(model.layers[3].get_weights()[0].shape[-1])\n",
        "    print(\"VALIDATION ACCURACY AFTER {} ITERATIONS = {}\".format(count+1,validation_accuracy))\n",
        "    count+=1\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Validation Accuracy = 0.9926999807357788\n",
            "431080 4586000\n",
            "ITERATION 1 \n",
            "Deleting 9/20 channels from layer: conv2d_1\n",
            "Deleting 21/50 channels from layer: conv2d_2\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0309 - val_accuracy: 0.9904\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.9902\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.0318 - val_accuracy: 0.9904\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0249 - val_accuracy: 0.9922\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0332 - val_accuracy: 0.9912\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0293 - val_accuracy: 0.9922\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0476 - val_accuracy: 0.9881\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0301 - val_accuracy: 0.9916\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0354 - val_accuracy: 0.9912\n",
            "245800 1811600\n",
            "VALIDATION ACCURACY AFTER 1 ITERATIONS = 0.9922000169754028\n",
            "ITERATION 2 \n",
            "Deleting 3/11 channels from layer: conv2d_1\n",
            "Deleting 7/29 channels from layer: conv2d_2\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            " - 2s - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0277 - val_accuracy: 0.9923\n",
            "Epoch 2/30\n",
            " - 2s - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0311 - val_accuracy: 0.9920\n",
            "Epoch 3/30\n",
            " - 2s - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0327 - val_accuracy: 0.9921\n",
            "Epoch 4/30\n",
            " - 2s - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0348 - val_accuracy: 0.9914\n",
            "Epoch 5/30\n",
            " - 2s - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0396 - val_accuracy: 0.9895\n",
            "Epoch 6/30\n",
            " - 2s - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0385 - val_accuracy: 0.9898\n",
            "Epoch 7/30\n",
            " - 2s - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0410 - val_accuracy: 0.9911\n",
            "Epoch 8/30\n",
            " - 2s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0356 - val_accuracy: 0.9916\n",
            "Epoch 9/30\n",
            " - 2s - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0405 - val_accuracy: 0.9915\n",
            "Epoch 10/30\n",
            " - 2s - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0357 - val_accuracy: 0.9922\n",
            "Epoch 11/30\n",
            " - 2s - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0369 - val_accuracy: 0.9928\n",
            "Epoch 12/30\n",
            " - 2s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0411 - val_accuracy: 0.9909\n",
            "Epoch 13/30\n",
            " - 2s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0381 - val_accuracy: 0.9923\n",
            "Epoch 14/30\n",
            " - 2s - loss: 2.7515e-04 - accuracy: 0.9999 - val_loss: 0.0370 - val_accuracy: 0.9935\n",
            "Epoch 15/30\n",
            " - 2s - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0462 - val_accuracy: 0.9896\n",
            "Epoch 16/30\n",
            " - 2s - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0454 - val_accuracy: 0.9915\n",
            "Epoch 17/30\n",
            " - 2s - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0446 - val_accuracy: 0.9916\n",
            "Epoch 18/30\n",
            " - 2s - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0485 - val_accuracy: 0.9900\n",
            "Epoch 19/30\n",
            " - 2s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0384 - val_accuracy: 0.9920\n",
            "Epoch 20/30\n",
            " - 2s - loss: 1.2089e-04 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9925\n",
            "Epoch 21/30\n",
            " - 2s - loss: 2.3523e-05 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9927\n",
            "Epoch 22/30\n",
            " - 2s - loss: 1.3266e-05 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9929\n",
            "Epoch 23/30\n",
            " - 2s - loss: 9.8218e-06 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9932\n",
            "Epoch 24/30\n",
            " - 2s - loss: 7.6831e-06 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9933\n",
            "Epoch 25/30\n",
            " - 2s - loss: 6.0329e-06 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9934\n",
            "Epoch 26/30\n",
            " - 2s - loss: 4.7929e-06 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9933\n",
            "Epoch 27/30\n",
            " - 2s - loss: 3.8058e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9933\n",
            "Epoch 28/30\n",
            " - 2s - loss: 3.0483e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            " - 2s - loss: 2.4566e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9934\n",
            "Epoch 30/30\n",
            " - 2s - loss: 1.9339e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
            "186140 1155600\n",
            "VALIDATION ACCURACY AFTER 2 ITERATIONS = 0.9934999942779541\n",
            "ITERATION 3 \n",
            "Deleting 1/8 channels from layer: conv2d_1\n",
            "Deleting 5/22 channels from layer: conv2d_2\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            " - 2s - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0439 - val_accuracy: 0.9899\n",
            "Epoch 2/30\n",
            " - 2s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0401 - val_accuracy: 0.9922\n",
            "Epoch 3/30\n",
            " - 2s - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0456 - val_accuracy: 0.9911\n",
            "Epoch 4/30\n",
            " - 2s - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0408 - val_accuracy: 0.9906\n",
            "Epoch 5/30\n",
            " - 2s - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0453 - val_accuracy: 0.9910\n",
            "Epoch 6/30\n",
            " - 2s - loss: 8.9022e-04 - accuracy: 0.9998 - val_loss: 0.0392 - val_accuracy: 0.9924\n",
            "Epoch 7/30\n",
            " - 2s - loss: 6.2628e-04 - accuracy: 0.9998 - val_loss: 0.0494 - val_accuracy: 0.9909\n",
            "Epoch 8/30\n",
            " - 2s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0549 - val_accuracy: 0.9899\n",
            "Epoch 9/30\n",
            " - 2s - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0480 - val_accuracy: 0.9908\n",
            "Epoch 10/30\n",
            " - 2s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0462 - val_accuracy: 0.9906\n",
            "Epoch 11/30\n",
            " - 2s - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0437 - val_accuracy: 0.9921\n",
            "Epoch 12/30\n",
            " - 2s - loss: 4.0645e-04 - accuracy: 0.9998 - val_loss: 0.0448 - val_accuracy: 0.9919\n",
            "Epoch 13/30\n",
            " - 2s - loss: 6.4174e-04 - accuracy: 0.9999 - val_loss: 0.0395 - val_accuracy: 0.9922\n",
            "Epoch 14/30\n",
            " - 2s - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0517 - val_accuracy: 0.9914\n",
            "Epoch 15/30\n",
            " - 2s - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0602 - val_accuracy: 0.9888\n",
            "Epoch 16/30\n",
            " - 2s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0539 - val_accuracy: 0.9910\n",
            "Epoch 17/30\n",
            " - 2s - loss: 2.4511e-04 - accuracy: 0.9999 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
            "Epoch 18/30\n",
            " - 2s - loss: 4.0102e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9923\n",
            "Epoch 19/30\n",
            " - 2s - loss: 1.2587e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9921\n",
            "Epoch 20/30\n",
            " - 2s - loss: 7.4584e-06 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9923\n",
            "Epoch 21/30\n",
            " - 2s - loss: 5.8723e-06 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9924\n",
            "Epoch 22/30\n",
            " - 2s - loss: 4.7721e-06 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9923\n",
            "Epoch 23/30\n",
            " - 2s - loss: 3.9053e-06 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9923\n",
            "Epoch 24/30\n",
            " - 2s - loss: 3.1885e-06 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9926\n",
            "Epoch 25/30\n",
            " - 2s - loss: 2.6299e-06 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9924\n",
            "Epoch 26/30\n",
            " - 2s - loss: 2.1522e-06 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9928\n",
            "Epoch 27/30\n",
            " - 2s - loss: 1.7707e-06 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9929\n",
            "Epoch 28/30\n",
            " - 2s - loss: 1.4323e-06 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9928\n",
            "Epoch 29/30\n",
            " - 2s - loss: 1.1654e-06 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9930\n",
            "Epoch 30/30\n",
            " - 2s - loss: 9.3673e-07 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9930\n",
            "144684 864400\n",
            "VALIDATION ACCURACY AFTER 3 ITERATIONS = 0.9929999709129333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcJvyh0U60Vu",
        "colab_type": "code",
        "outputId": "ec8f7663-9185-4c63-e3a2-72a7d5b5669a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 7)         182       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 17)          2992      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               136500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 144,684\n",
            "Trainable params: 144,684\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6-J_KDz2kM1",
        "colab_type": "code",
        "outputId": "82292980-2bbc-4086-e51f-d1168930acec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "l1_norms = my_get_l1_norms_filters_per_epoch(weight_list_per_epoch)\n",
        "distance_matrix_list = my_get_distance_matrix_list(l1_norms)\n",
        "episodes_for_all_layers = my_get_episodes_for_all_layers(distance_matrix_list,95)\n",
        "filter_pruning_indices = my_get_filter_pruning_indices(episodes_for_all_layers,l1_norms)\n",
        "print(filter_pruning_indices[0][:1],filter_pruning_indices[1][:6])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] [1, 2, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsfAYrKj2x2O",
        "colab_type": "code",
        "outputId": "c8495e8b-3387-4f4a-89a2-3911edccecd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "\n",
        "surgeon = Surgeon(model)\n",
        "surgeon.add_job('delete_channels',model.layers[1],channels = filter_pruning_indices[0][:1])\n",
        "surgeon.add_job('delete_channels',model.layers[3],channels =filter_pruning_indices[1][:1])\n",
        "model = surgeon.operate()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting 1/3 channels from layer: conv2d_1\n",
            "Deleting 1/4 channels from layer: conv2d_2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug3JpdQ_mL7B",
        "colab_type": "code",
        "outputId": "743f20b2-0fd1-4a05-80f7-db6459b1da8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 2)         52        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 3)           153       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               24500     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 29,715\n",
            "Trainable params: 29,715\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1TsjomcaPLD",
        "colab_type": "code",
        "outputId": "6a75f35a-a3c9-4ff8-8567-1bed88460a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model,history,weight_list_per_epoch = train(model,60,False)\n",
        "\n",
        "best_acc_index = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
        "log_dict['train_loss'].append(history.history['loss'][best_acc_index])\n",
        "log_dict['train_acc'].append(history.history['accuracy'][best_acc_index])\n",
        "log_dict['val_loss'].append(history.history['val_loss'][best_acc_index])\n",
        "log_dict['val_acc'].append(history.history['val_accuracy'][best_acc_index])\n",
        "a,b = count_model_params_flops(model,False)\n",
        "log_dict['total_params'].append(a)\n",
        "log_dict['total_flops'].append(b)\n",
        "log_dict['filters_in_conv1'].append(model.layers[1].get_weights()[0].shape[-1])\n",
        "log_dict['filters_in_conv2'].append(model.layers[3].get_weights()[0].shape[-1])\n",
        "print(\"Final Validation Accuracy = \",(max(history.history['val_accuracy'])*100))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/60\n",
            " - 3s - loss: 0.2085 - accuracy: 0.9602 - val_loss: 0.1266 - val_accuracy: 0.9689\n",
            "Epoch 2/60\n",
            " - 2s - loss: 0.0705 - accuracy: 0.9796 - val_loss: 0.0966 - val_accuracy: 0.9745\n",
            "Epoch 3/60\n",
            " - 2s - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.0916 - val_accuracy: 0.9761\n",
            "Epoch 4/60\n",
            " - 2s - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.0846 - val_accuracy: 0.9781\n",
            "Epoch 5/60\n",
            " - 2s - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0870 - val_accuracy: 0.9796\n",
            "Epoch 6/60\n",
            " - 2s - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.0862 - val_accuracy: 0.9792\n",
            "Epoch 7/60\n",
            " - 2s - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0849 - val_accuracy: 0.9800\n",
            "Epoch 8/60\n",
            " - 2s - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0883 - val_accuracy: 0.9794\n",
            "Epoch 9/60\n",
            " - 2s - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0887 - val_accuracy: 0.9807\n",
            "Epoch 10/60\n",
            " - 2s - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0920 - val_accuracy: 0.9802\n",
            "Epoch 11/60\n",
            " - 2s - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0936 - val_accuracy: 0.9798\n",
            "Epoch 12/60\n",
            " - 2s - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0998 - val_accuracy: 0.9796\n",
            "Epoch 13/60\n",
            " - 2s - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1082 - val_accuracy: 0.9801\n",
            "Epoch 14/60\n",
            " - 2s - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1053 - val_accuracy: 0.9803\n",
            "Epoch 15/60\n",
            " - 2s - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1047 - val_accuracy: 0.9808\n",
            "Epoch 16/60\n",
            " - 2s - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1095 - val_accuracy: 0.9795\n",
            "Epoch 17/60\n",
            " - 2s - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1029 - val_accuracy: 0.9810\n",
            "Epoch 18/60\n",
            " - 2s - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1028 - val_accuracy: 0.9809\n",
            "Epoch 19/60\n",
            " - 2s - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1040 - val_accuracy: 0.9827\n",
            "Epoch 20/60\n",
            " - 2s - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1148 - val_accuracy: 0.9799\n",
            "Epoch 21/60\n",
            " - 2s - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1179 - val_accuracy: 0.9807\n",
            "Epoch 22/60\n",
            " - 2s - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.1123 - val_accuracy: 0.9820\n",
            "Epoch 23/60\n",
            " - 2s - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1143 - val_accuracy: 0.9815\n",
            "Epoch 24/60\n",
            " - 2s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1062 - val_accuracy: 0.9822\n",
            "Epoch 25/60\n",
            " - 2s - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1283 - val_accuracy: 0.9796\n",
            "Epoch 26/60\n",
            " - 2s - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1183 - val_accuracy: 0.9825\n",
            "Epoch 27/60\n",
            " - 2s - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1169 - val_accuracy: 0.9814\n",
            "Epoch 28/60\n",
            " - 2s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1110 - val_accuracy: 0.9827\n",
            "Epoch 29/60\n",
            " - 2s - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1298 - val_accuracy: 0.9800\n",
            "Epoch 30/60\n",
            " - 2s - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.1287 - val_accuracy: 0.9807\n",
            "Epoch 31/60\n",
            " - 2s - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.1298 - val_accuracy: 0.9804\n",
            "Epoch 32/60\n",
            " - 2s - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1205 - val_accuracy: 0.9822\n",
            "Epoch 33/60\n",
            " - 2s - loss: 7.3732e-04 - accuracy: 0.9998 - val_loss: 0.1156 - val_accuracy: 0.9822\n",
            "Epoch 34/60\n",
            " - 2s - loss: 1.4442e-04 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9824\n",
            "Epoch 35/60\n",
            " - 2s - loss: 2.0239e-04 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9829\n",
            "Epoch 36/60\n",
            " - 2s - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1488 - val_accuracy: 0.9781\n",
            "Epoch 37/60\n",
            " - 2s - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1263 - val_accuracy: 0.9801\n",
            "Epoch 38/60\n",
            " - 2s - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1224 - val_accuracy: 0.9818\n",
            "Epoch 39/60\n",
            " - 2s - loss: 4.1468e-04 - accuracy: 0.9999 - val_loss: 0.1188 - val_accuracy: 0.9822\n",
            "Epoch 40/60\n",
            " - 2s - loss: 3.4577e-04 - accuracy: 0.9999 - val_loss: 0.1186 - val_accuracy: 0.9829\n",
            "Epoch 41/60\n",
            " - 2s - loss: 9.4176e-05 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9829\n",
            "Epoch 42/60\n",
            " - 2s - loss: 6.5640e-05 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9827\n",
            "Epoch 43/60\n",
            " - 2s - loss: 5.2777e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9830\n",
            "Epoch 44/60\n",
            " - 2s - loss: 4.3575e-05 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9831\n",
            "Epoch 45/60\n",
            " - 2s - loss: 3.6969e-05 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9831\n",
            "Epoch 46/60\n",
            " - 2s - loss: 3.1144e-05 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9836\n",
            "Epoch 47/60\n",
            " - 2s - loss: 2.6321e-05 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9841\n",
            "Epoch 48/60\n",
            " - 2s - loss: 2.2703e-05 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9838\n",
            "Epoch 49/60\n",
            " - 2s - loss: 1.8610e-05 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9841\n",
            "Epoch 50/60\n",
            " - 2s - loss: 1.5541e-05 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9837\n",
            "Epoch 51/60\n",
            " - 2s - loss: 1.2993e-05 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9842\n",
            "Epoch 52/60\n",
            " - 2s - loss: 1.1021e-05 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9844\n",
            "Epoch 53/60\n",
            " - 2s - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.1813 - val_accuracy: 0.9772\n",
            "Epoch 54/60\n",
            " - 2s - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1292 - val_accuracy: 0.9809\n",
            "Epoch 55/60\n",
            " - 2s - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1266 - val_accuracy: 0.9821\n",
            "Epoch 56/60\n",
            " - 2s - loss: 7.1806e-04 - accuracy: 0.9998 - val_loss: 0.1270 - val_accuracy: 0.9827\n",
            "Epoch 57/60\n",
            " - 2s - loss: 1.7116e-04 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9825\n",
            "Epoch 58/60\n",
            " - 2s - loss: 7.6847e-05 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9827\n",
            "Epoch 59/60\n",
            " - 2s - loss: 5.6016e-05 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9830\n",
            "Epoch 60/60\n",
            " - 2s - loss: 4.5422e-05 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9829\n",
            "Final Validation Accuracy =  98.43999743461609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6x5C1eFBSXJ",
        "colab_type": "code",
        "outputId": "3e87b392-95d6-4288-d24a-4c041ffd6734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_flops = count_model_params_flops(model,False)[1]\n",
        "print(\"Total reduction in Flops in Conv layers = {}%\".format(((initial_flops-final_flops)/initial_flops)*100))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total reduction in Flops in Conv layers = 97.06061927605757%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES_-ddmzEklQ",
        "colab_type": "code",
        "outputId": "70306e66-e33a-4137-b345-0961fa92e356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 2)         52        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 3)           153       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               24500     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 29,715\n",
            "Trainable params: 29,715\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "730rifL3iP1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}