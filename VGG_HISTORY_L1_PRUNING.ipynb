{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_HISTORY_L1_PRUNING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDfarazuddin99/CNN_Pruning/blob/master/VGG_HISTORY_L1_PRUNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obetfYGYdj2K",
        "colab_type": "code",
        "outputId": "96538873-a91c-4da5-ad66-e0526f0e0a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "# !pip install tesnsorflow 1.x\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D,BatchNormalization,Activation\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "\n",
        "!pip install kerassurgeon\n",
        "from kerassurgeon import identify \n",
        "from kerassurgeon.operations import delete_channels,delete_layer\n",
        "from kerassurgeon import Surgeon\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kerassurgeon in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from kerassurgeon) (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kLqwFFSUGY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def my_get_all_conv_layers(model , first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> type boolean \n",
        "            first_time = True => model is not pruned \n",
        "            first_time = False => model is pruned\n",
        "    Return:\n",
        "        List of Indices containing convolution layers\n",
        "    '''\n",
        "\n",
        "    all_conv_layers = list()\n",
        "    for i,each_layer in enumerate(model.layers):\n",
        "        if (each_layer.name[0:6] == 'conv2d'):\n",
        "            all_conv_layers.append(i)\n",
        "    return all_conv_layers if (first_time==True) else all_conv_layers[1:]\n",
        "\n",
        "\n",
        "def my_get_all_dense_layers(model):\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model        \n",
        "    Return:\n",
        "        List of Indices containing fully connected layers\n",
        "    '''\n",
        "    all_dense_layers = list()\n",
        "    for i,each_layer in enumerate(model.layers):\n",
        "        if (each_layer.name[0:5] == 'dense'):\n",
        "            all_dense_layers.append(i)\n",
        "    return all_dense_layers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def count_conv_params_flops(conv_layer):\n",
        "    # out shape is  n_cells_dim1 * (n_cells_dim2 * n_cells_dim3)\n",
        "    '''\n",
        "    Arguments:\n",
        "        conv layer \n",
        "    Return:\n",
        "        Number of Parameters, Number of Flops\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    out_shape = conv_layer.output.shape.as_list()\n",
        "    n_cells_total = np.prod(out_shape[1:-1])\n",
        "\n",
        "    n_conv_params_total = conv_layer.count_params()\n",
        "\n",
        "    conv_flops = n_conv_params_total * n_cells_total\n",
        "\n",
        " \n",
        "\n",
        "    return n_conv_params_total, conv_flops\n",
        "\n",
        "\n",
        "def count_dense_params_flops(dense_layer):\n",
        "    # out shape is  n_cells_dim1 * (n_cells_dim2 * n_cells_dim3)\n",
        "    '''\n",
        "    Arguments:\n",
        "      dense layer \n",
        "    Return:\n",
        "        Number of Parameters, Number of Flops\n",
        "\n",
        "    '''\n",
        "\n",
        "    out_shape = dense_layer.output.shape.as_list()\n",
        "    n_cells_total = np.prod(out_shape[1:-1])\n",
        "\n",
        "    n_dense_params_total = dense_layer.count_params()\n",
        "\n",
        "    dense_flops = n_dense_params_total\n",
        "\n",
        "\n",
        "    return n_dense_params_total, dense_flops\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def count_model_params_flops(model,first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> boolean variable\n",
        "        first_time = True => model is not pruned \n",
        "        first_time = False => model is pruned\n",
        "    Return:\n",
        "        Number of parmaters, Number of Flops\n",
        "    '''\n",
        "\n",
        "    total_params = 0\n",
        "    total_flops = 0\n",
        "    # if first_time == True:\n",
        "    #     model_layers = model.layers\n",
        "    # else:\n",
        "    #     model_layers = model.layers[1:-2]\n",
        "    # all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "    # all_dense_layers = my_get_all_dense_layers(model)\n",
        "    # model_layers = list()\n",
        "    \n",
        "    # for i in all_conv_layers:\n",
        "    #     model_layers.append(model.layers[i])\n",
        "    # for i in all_dense_layers:\n",
        "    #     model_layers.append(model.layers[i])\n",
        "    model_layers = model.layers[1:-2]\n",
        "    for index,layer in enumerate(model_layers):\n",
        "        if any(conv_type in str(type(layer)) for conv_type in ['Conv1D', 'Conv2D', 'Conv3D']):\n",
        "            print(index,layer.name)\n",
        "            params, flops = count_conv_params_flops(layer)\n",
        "            total_params += params\n",
        "            total_flops += flops\n",
        "        elif 'Dense' in str(type(layer)):\n",
        "            print(index,layer.name) \n",
        "            params, flops = count_dense_params_flops(layer)\n",
        "            total_params += params\n",
        "            total_flops += flops\n",
        "    return total_params, total_flops\n",
        "\n",
        "def my_get_weights_in_conv_layers(model,first_time):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        model -> your model\n",
        "        first_time -> boolean variable\n",
        "            first_time = True => model is not pruned \n",
        "            first_time = False => model is pruned\n",
        "    Return:\n",
        "        List containing weight tensors of each layer\n",
        "    '''\n",
        "    \n",
        "\n",
        "\n",
        "  weights = list()\n",
        "  all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "  layer_wise_weights = list() \n",
        "  for i in all_conv_layers:\n",
        "        weights.append(model.layers[i].get_weights()[0])  \n",
        "  return weights\n",
        "\n",
        "def my_get_l1_norms_filters_per_epoch(weight_list_per_epoch):\n",
        "\n",
        "    '''\n",
        "    Arguments:\n",
        "        List\n",
        "    Return:\n",
        "        Number of parmaters, Number of Flops\n",
        "    '''\n",
        "    \n",
        "    # weight_list_per_epoch = my_get_weights_in_conv_layers(model,first_time)\n",
        "    l1_norms_filters_per_epoch = list()\n",
        "    \n",
        "\n",
        "    for index in range(len(weight_list_per_epoch)):\n",
        "\n",
        "        epochs = np.array(weight_list_per_epoch[index]).shape[0]\n",
        "        h , w , d = np.array(weight_list_per_epoch[index]).shape[1], np.array(weight_list_per_epoch[index]).shape[2] , np.array(weight_list_per_epoch[index]).shape[3]\n",
        "\n",
        "\n",
        "        l1_norms_filters_per_epoch.append(np.sum(np.array(weight_list_per_epoch[index]).reshape(epochs,h*w*d,-1),axis=1))\n",
        "    return l1_norms_filters_per_epoch\n",
        "\n",
        "def my_in_conv_layers_get_sum_of_l1_norms_sorted_indices(weight_list_per_epoch):\n",
        "    layer_wise_filter_sorted_indices = list()\n",
        "    layer_wise_filter_sorted_values = list()\n",
        "    l1_norms_filters_per_epoch = my_get_l1_norms_filters_per_epoch(weight_list_per_epoch)\n",
        "    sum_l1_norms = list()\n",
        "    \n",
        "    for i in l1_norms_filters_per_epoch:\n",
        "        sum_l1_norms.append(np.sum(i,axis=0))\n",
        "    \n",
        "    layer_wise_filter_sorted_indices = list()\n",
        "    \n",
        "    for i in sum_l1_norms:\n",
        "        a = pd.Series(i).sort_values().index\n",
        "        layer_wise_filter_sorted_indices.append(a.tolist())\n",
        "    return layer_wise_filter_sorted_indices\n",
        "\n",
        "\n",
        "def my_get_percent_prune_filter_indices(layer_wise_filter_sorted_indices,percentage):    \n",
        "\n",
        "    prune_filter_indices = list()\n",
        "    for i in range(len(layer_wise_filter_sorted_indices)):\n",
        "        prune_filter_indices.append(int(len(layer_wise_filter_sorted_indices[i]) * (percentage/100))   )\n",
        "    return prune_filter_indices\n",
        "\n",
        "\n",
        "\n",
        "def my_delete_filters(model,weight_list_per_epoch,percentage,first_time):\n",
        "\n",
        "    sum_of_l1_norms_sorted_indices = my_in_conv_layers_get_sum_of_l1_norms_sorted_indices(weight_list_per_epoch)\n",
        "\n",
        "    layer_wise_filter_sorted_indices = my_in_conv_layers_get_sum_of_l1_norms_sorted_indices(weight_list_per_epoch)\n",
        "    # print(layer_wise_filter_sorted_indices)\n",
        "    prune_filter_indices = my_get_percent_prune_filter_indices(layer_wise_filter_sorted_indices,percentage)\n",
        "    # print(prune_filter_indices)\n",
        "    all_conv_layers = my_get_all_conv_layers(model,first_time)\n",
        "\n",
        "    surgeon = Surgeon(model)\n",
        "    for index,value in enumerate(all_conv_layers):\n",
        "        # print(index,value,layer_wise_filter_sorted_indices[index][0:prune_filter_indices[index]])\n",
        "        surgeon.add_job('delete_channels',model.layers[value],channels = layer_wise_filter_sorted_indices[index][0:prune_filter_indices[index]])\n",
        "\n",
        "    model_new = surgeon.operate()\n",
        " \n",
        "    \n",
        "    return model_new\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10e7dA64dv4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Get_Weights(Callback):\n",
        "    def __init__(self,first_time):\n",
        "        super(Get_Weights, self).__init__()\n",
        "        self.weight_list = [] #Using a list of list to store weight tensors per epoch\n",
        "        self.first_time = first_time\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        if epoch == 0:\n",
        "            all_conv_layers = my_get_all_conv_layers(self.model,self.first_time)\n",
        "            for i in range(len(all_conv_layers)):\n",
        "                self.weight_list.append([]) # appending empty lists for later appending weight tensors \n",
        "        \n",
        "        for index,each_weight in enumerate(my_get_weights_in_conv_layers(self.model,self.first_time)):\n",
        "                self.weight_list[index].append(each_weight)  \n",
        "\n",
        "\n",
        "\n",
        "class cifar10vgg:\n",
        "\n",
        "    def __init__(self,first_time,epochs,train=True):\n",
        "        self.epochs = epochs\n",
        "        self.first_time = first_time\n",
        "        self.num_classes = 10\n",
        "        self.weight_decay = 0.0005\n",
        "        self.x_shape = [32,32,3]\n",
        "        self.history = 0\n",
        "        self.weight_list_per_epoch = None\n",
        "        self.model = self.build_model()\n",
        "        if train:\n",
        "            self.model, self.history ,self.weight_list_per_epoch = self.train(self.model)\n",
        "        else:\n",
        "            self.model.load_weights('drive/My Drive/Colab Notebooks/cifar10vgg.h5')\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
        "\n",
        "        model = Sequential()\n",
        "        weight_decay = self.weight_decay\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.num_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "        return model\n",
        "\n",
        "\n",
        "    def normalize(self,X_train,X_test):\n",
        "        #this function normalize inputs for zero mean and unit variance\n",
        "        # it is used when training a model.\n",
        "        # Input: training set and test set\n",
        "        # Output: normalized training set and test set according to the trianing set statistics.\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7)\n",
        "        return X_train, X_test\n",
        "\n",
        "\n",
        "    def train(self,model):\n",
        "\n",
        "        #training parameters\n",
        "        batch_size = 128\n",
        "        maxepoches = 250\n",
        "        learning_rate = 0.1\n",
        "        lr_decay = 1e-6\n",
        "        lr_drop = 20\n",
        "        # The data, shuffled and split between train and test sets:\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train, x_test = self.normalize(x_train, x_test)\n",
        "\n",
        "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
        "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "        def lr_scheduler(epoch):\n",
        "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "        save_model = ModelCheckpoint('drive/My Drive/Colab Notebooks/pruned_cifarvgg.h5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "        #data augmentation\n",
        "        datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=False)  # randomly flip images\n",
        "        # (std, mean, and principal components if ZCA whitening is applied).\n",
        "        # datagen.fit(x_train)\n",
        "\n",
        "\n",
        "\n",
        "        #optimization details\n",
        "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "        gw = Get_Weights(self.first_time)\n",
        "\n",
        "        # training process in a for loop with learning rate drop every 25 epoches.\n",
        "\n",
        "        history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                         batch_size=batch_size),\n",
        "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                            epochs=self.epochs,\n",
        "                            validation_data=(x_test, y_test),callbacks=[reduce_lr, save_model,gw],verbose=1)\n",
        "        #model.save_weights('cifar10vgg.h5')\n",
        "        return model, history,gw.weight_list\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-blYLXw6DAIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(X_train,X_test):\n",
        "    #this function normalize inputs for zero mean and unit variance\n",
        "    # it is used when training a model.\n",
        "    # Input: training set and test set\n",
        "    # Output: normalized training set and test set according to the trianing set statistics.\n",
        "    mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "    X_train = (X_train-mean)/(std+1e-7)\n",
        "    X_test = (X_test-mean)/(std+1e-7)\n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def train(model,epochs):\n",
        "\n",
        "    #training parameters\n",
        "    batch_size = 128\n",
        "    maxepoches = 250\n",
        "    learning_rate = 0.1\n",
        "    lr_decay = 1e-6\n",
        "    lr_drop = 20\n",
        "\n",
        "    num_classes = 10\n",
        "    weight_decay = 0.0005\n",
        "    x_shape = [32,32,3]\n",
        "\n",
        "    # The data, shuffled and split between train and test sets:\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train, x_test = normalize(x_train, x_test)\n",
        "\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    def lr_scheduler(epoch):\n",
        "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "    save_model = ModelCheckpoint('drive/My Drive/Colab Notebooks/pruned_cifarvgg.h5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "    #data augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    # datagen.fit(x_train)\n",
        "\n",
        "\n",
        "\n",
        "    #optimization details\n",
        "    sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "    gw = Get_Weights(False)\n",
        "\n",
        "    # training process in a for loop with learning rate drop every 25 epoches.\n",
        "\n",
        "    history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                        batch_size=batch_size),\n",
        "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),callbacks=[reduce_lr, save_model,gw],verbose=1)\n",
        "    #model.save_weights('cifar10vgg.h5')\n",
        "    return model, history,gw.weight_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtFfW0W6EBpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfac40c9-7c1a-4b1d-d702-70f062389247"
      },
      "source": [
        "# m = my_delete_filters(my_model,weight_list_per_epoch,30,True)\n",
        "# train for first time\n",
        "my_vgg = cifar10vgg(first_time=True,epochs=20)\n",
        "model, history ,weight_list_per_epoch= my_vgg.model, my_vgg.history, my_vgg.weight_list_per_epoch\n",
        "\n",
        "\n",
        "#this dictionary is to log the parameters and is later converted into a dataframe.\n",
        "log_dict = dict()\n",
        "log_dict['train_loss'] = []\n",
        "log_dict['train_acc'] = []\n",
        "log_dict['val_loss'] = []\n",
        "log_dict['val_acc'] = []\n",
        "log_dict['total_params'] = []\n",
        "log_dict['total_flops'] = []\n",
        "\n",
        "best_acc_index = history.history['val_acc'].index(max(history.history['val_acc']))\n",
        "log_dict['train_loss'].append(history.history['loss'][best_acc_index])\n",
        "log_dict['train_acc'].append(history.history['acc'][best_acc_index])\n",
        "log_dict['val_loss'].append(history.history['val_loss'][best_acc_index])\n",
        "log_dict['val_acc'].append(history.history['val_acc'][best_acc_index])\n",
        "a,b = count_model_params_flops(model,True)\n",
        "log_dict['total_params'].append(a)\n",
        "log_dict['total_flops'].append(b)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "390/390 [==============================] - 57s 145ms/step - loss: 19.5526 - acc: 0.2146 - val_loss: 19.6632 - val_acc: 0.1281\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 10.5674 - acc: 0.2966 - val_loss: 8.8999 - val_acc: 0.1608\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 7.0928 - acc: 0.2637 - val_loss: 6.4324 - val_acc: 0.2408\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 50s 128ms/step - loss: 7.3277 - acc: 0.2789 - val_loss: 7.3206 - val_acc: 0.1694\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 5.5498 - acc: 0.3499 - val_loss: 4.7100 - val_acc: 0.3092\n",
            "Epoch 6/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 3.5751 - acc: 0.4543 - val_loss: 3.3164 - val_acc: 0.3322\n",
            "Epoch 7/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 2.4349 - acc: 0.5341 - val_loss: 2.0955 - val_acc: 0.5744\n",
            "Epoch 8/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 1.9121 - acc: 0.5904 - val_loss: 1.9214 - val_acc: 0.5630\n",
            "Epoch 9/20\n",
            "390/390 [==============================] - 49s 127ms/step - loss: 1.6918 - acc: 0.6327 - val_loss: 1.6570 - val_acc: 0.6523\n",
            "Epoch 10/20\n",
            "390/390 [==============================] - 49s 127ms/step - loss: 1.6047 - acc: 0.6559 - val_loss: 1.5452 - val_acc: 0.6816\n",
            "Epoch 11/20\n",
            "390/390 [==============================] - 49s 126ms/step - loss: 1.5269 - acc: 0.6825 - val_loss: 1.5130 - val_acc: 0.6887\n",
            "Epoch 12/20\n",
            "390/390 [==============================] - 49s 126ms/step - loss: 1.4967 - acc: 0.6940 - val_loss: 1.5345 - val_acc: 0.6840\n",
            "Epoch 13/20\n",
            "390/390 [==============================] - 49s 127ms/step - loss: 1.4708 - acc: 0.7043 - val_loss: 1.5450 - val_acc: 0.6948\n",
            "Epoch 14/20\n",
            "390/390 [==============================] - 49s 127ms/step - loss: 1.4669 - acc: 0.7110 - val_loss: 1.4109 - val_acc: 0.7345\n",
            "Epoch 15/20\n",
            "390/390 [==============================] - 50s 128ms/step - loss: 1.4517 - acc: 0.7219 - val_loss: 1.4026 - val_acc: 0.7333\n",
            "Epoch 16/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 1.4596 - acc: 0.7232 - val_loss: 1.4300 - val_acc: 0.7351\n",
            "Epoch 17/20\n",
            "390/390 [==============================] - 50s 128ms/step - loss: 1.4609 - acc: 0.7275 - val_loss: 1.4895 - val_acc: 0.7230\n",
            "Epoch 18/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 1.4689 - acc: 0.7300 - val_loss: 1.4308 - val_acc: 0.7536\n",
            "Epoch 19/20\n",
            "390/390 [==============================] - 49s 127ms/step - loss: 1.4761 - acc: 0.7343 - val_loss: 1.4010 - val_acc: 0.7631\n",
            "Epoch 20/20\n",
            "390/390 [==============================] - 50s 127ms/step - loss: 1.4855 - acc: 0.7360 - val_loss: 1.4866 - val_acc: 0.7394\n",
            "3 conv2d_15\n",
            "7 conv2d_16\n",
            "11 conv2d_17\n",
            "15 conv2d_18\n",
            "19 conv2d_19\n",
            "23 conv2d_20\n",
            "27 conv2d_21\n",
            "31 conv2d_22\n",
            "35 conv2d_23\n",
            "39 conv2d_24\n",
            "43 conv2d_25\n",
            "47 conv2d_26\n",
            "53 dense_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-iRhLdSH5FN",
        "colab_type": "code",
        "outputId": "0cd319e2-092c-4f8c-b283-486cb4e4f2b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,001,418\n",
            "Trainable params: 14,991,946\n",
            "Non-trainable params: 9,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR3pjKtMbs5I",
        "colab_type": "code",
        "outputId": "a31b3483-fc0b-4a4b-9484-8fb948f839b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#stop pruning if the accuracy drops by 5% from maximum accuracy ever obtained. \n",
        "validation_accuracy = max(history.history['val_acc'])\n",
        "max_val_acc = validation_accuracy\n",
        "count = 0\n",
        "all_models = list()\n",
        "while validation_accuracy - max_val_acc >= -0.05 :\n",
        "\n",
        "# # while max_val_acc <= validation_accuracy  :\n",
        "\n",
        "    print(\"ITERATION {} \".format(count+1))\n",
        "    all_models.append(model)\n",
        "    if max_val_acc < validation_accuracy:\n",
        "        max_val_acc = validation_accuracy\n",
        "        \n",
        "\n",
        "    if count < 1:\n",
        "        model = my_delete_filters(model,weight_list_per_epoch,10,True)\n",
        "\n",
        "   \n",
        "    else:\n",
        "        model = my_delete_filters(model,weight_list_per_epoch,10,False)\n",
        "    \n",
        "    \n",
        "    a,b = count_model_params_flops(model,False)\n",
        "    model,history,weight_list_per_epoch = train(model,10)\n",
        "\n",
        "    validation_accuracy = max(history.history['val_acc'])\n",
        "    best_acc_index = history.history['val_acc'].index(max(history.history['val_acc']))\n",
        "    log_dict['train_loss'].append(history.history['loss'][best_acc_index])\n",
        "    log_dict['train_acc'].append(history.history['acc'][best_acc_index])\n",
        "    log_dict['val_loss'].append(history.history['val_loss'][best_acc_index])\n",
        "    log_dict['val_acc'].append(history.history['val_acc'][best_acc_index])\n",
        "    log_dict['total_params'].append(a)\n",
        "    log_dict['total_flops'].append(b)\n",
        "\n",
        "    print(\"VALIDATION ACCURACY AFTER {} ITERATIONS = {}\".format(count+1,validation_accuracy))\n",
        "    count+=1\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ITERATION 1 \n",
            "Deleting 6/64 channels from layer: conv2d_14\n",
            "Deleting 6/64 channels from layer: conv2d_15\n",
            "Deleting 12/128 channels from layer: conv2d_16\n",
            "Deleting 12/128 channels from layer: conv2d_17\n",
            "Deleting 25/256 channels from layer: conv2d_18\n",
            "Deleting 25/256 channels from layer: conv2d_19\n",
            "Deleting 25/256 channels from layer: conv2d_20\n",
            "Deleting 51/512 channels from layer: conv2d_21\n",
            "Deleting 51/512 channels from layer: conv2d_22\n",
            "Deleting 51/512 channels from layer: conv2d_23\n",
            "Deleting 51/512 channels from layer: conv2d_24\n",
            "Deleting 51/512 channels from layer: conv2d_25\n",
            "Deleting 51/512 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 53s 136ms/step - loss: 1.4626 - acc: 0.7226 - val_loss: 1.5553 - val_acc: 0.7239\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.4708 - acc: 0.7341 - val_loss: 1.5352 - val_acc: 0.7133\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.4847 - acc: 0.7365 - val_loss: 1.3706 - val_acc: 0.7739\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.4886 - acc: 0.7401 - val_loss: 1.3773 - val_acc: 0.7747\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.4973 - acc: 0.7391 - val_loss: 1.4158 - val_acc: 0.7556\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.4998 - acc: 0.7408 - val_loss: 1.4690 - val_acc: 0.7562\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.5033 - acc: 0.7417 - val_loss: 1.4356 - val_acc: 0.7657\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.5139 - acc: 0.7398 - val_loss: 1.4344 - val_acc: 0.7697\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.5072 - acc: 0.7455 - val_loss: 1.4456 - val_acc: 0.7661\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.5078 - acc: 0.7463 - val_loss: 1.3995 - val_acc: 0.7833\n",
            "VALIDATION ACCURACY AFTER 1 ITERATIONS = 0.7833\n",
            "ITERATION 2 \n",
            "Deleting 5/58 channels from layer: conv2d_14\n",
            "Deleting 5/58 channels from layer: conv2d_15\n",
            "Deleting 11/116 channels from layer: conv2d_16\n",
            "Deleting 11/116 channels from layer: conv2d_17\n",
            "Deleting 23/231 channels from layer: conv2d_18\n",
            "Deleting 23/231 channels from layer: conv2d_19\n",
            "Deleting 23/231 channels from layer: conv2d_20\n",
            "Deleting 46/461 channels from layer: conv2d_21\n",
            "Deleting 46/461 channels from layer: conv2d_22\n",
            "Deleting 46/461 channels from layer: conv2d_23\n",
            "Deleting 46/461 channels from layer: conv2d_24\n",
            "Deleting 46/461 channels from layer: conv2d_25\n",
            "Deleting 46/461 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 49s 127ms/step - loss: 1.4927 - acc: 0.7264 - val_loss: 1.4235 - val_acc: 0.7685\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5127 - acc: 0.7331 - val_loss: 1.4258 - val_acc: 0.7705\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5107 - acc: 0.7377 - val_loss: 1.4307 - val_acc: 0.7674\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5321 - acc: 0.7340 - val_loss: 1.5428 - val_acc: 0.7313\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5327 - acc: 0.7373 - val_loss: 1.6555 - val_acc: 0.6998\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5136 - acc: 0.7433 - val_loss: 1.4620 - val_acc: 0.7568\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5241 - acc: 0.7430 - val_loss: 1.4490 - val_acc: 0.7739\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5289 - acc: 0.7415 - val_loss: 1.4065 - val_acc: 0.7853\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5206 - acc: 0.7434 - val_loss: 1.3946 - val_acc: 0.7820\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 1.5287 - acc: 0.7429 - val_loss: 1.4501 - val_acc: 0.7644\n",
            "VALIDATION ACCURACY AFTER 2 ITERATIONS = 0.7853\n",
            "ITERATION 3 \n",
            "Deleting 5/53 channels from layer: conv2d_14\n",
            "Deleting 5/53 channels from layer: conv2d_15\n",
            "Deleting 10/105 channels from layer: conv2d_16\n",
            "Deleting 10/105 channels from layer: conv2d_17\n",
            "Deleting 20/208 channels from layer: conv2d_18\n",
            "Deleting 20/208 channels from layer: conv2d_19\n",
            "Deleting 20/208 channels from layer: conv2d_20\n",
            "Deleting 41/415 channels from layer: conv2d_21\n",
            "Deleting 41/415 channels from layer: conv2d_22\n",
            "Deleting 41/415 channels from layer: conv2d_23\n",
            "Deleting 41/415 channels from layer: conv2d_24\n",
            "Deleting 41/415 channels from layer: conv2d_25\n",
            "Deleting 41/415 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.5131 - acc: 0.7193 - val_loss: 1.4083 - val_acc: 0.7593\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.5320 - acc: 0.7308 - val_loss: 1.5411 - val_acc: 0.7214\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5193 - acc: 0.7330 - val_loss: 1.7691 - val_acc: 0.6778\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5230 - acc: 0.7352 - val_loss: 1.5117 - val_acc: 0.7535\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5209 - acc: 0.7374 - val_loss: 1.4232 - val_acc: 0.7590\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.5221 - acc: 0.7382 - val_loss: 1.4742 - val_acc: 0.7571\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.5256 - acc: 0.7362 - val_loss: 1.3912 - val_acc: 0.7843\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 1.5244 - acc: 0.7372 - val_loss: 1.4749 - val_acc: 0.7508\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 1.5186 - acc: 0.7388 - val_loss: 1.4719 - val_acc: 0.7565\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 1.5202 - acc: 0.7398 - val_loss: 1.3796 - val_acc: 0.7819\n",
            "VALIDATION ACCURACY AFTER 3 ITERATIONS = 0.7843\n",
            "ITERATION 4 \n",
            "Deleting 4/48 channels from layer: conv2d_14\n",
            "Deleting 4/48 channels from layer: conv2d_15\n",
            "Deleting 9/95 channels from layer: conv2d_16\n",
            "Deleting 9/95 channels from layer: conv2d_17\n",
            "Deleting 18/188 channels from layer: conv2d_18\n",
            "Deleting 18/188 channels from layer: conv2d_19\n",
            "Deleting 18/188 channels from layer: conv2d_20\n",
            "Deleting 37/374 channels from layer: conv2d_21\n",
            "Deleting 37/374 channels from layer: conv2d_22\n",
            "Deleting 37/374 channels from layer: conv2d_23\n",
            "Deleting 37/374 channels from layer: conv2d_24\n",
            "Deleting 37/374 channels from layer: conv2d_25\n",
            "Deleting 37/374 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 48s 124ms/step - loss: 1.5077 - acc: 0.7190 - val_loss: 1.3724 - val_acc: 0.7751\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 1.5244 - acc: 0.7305 - val_loss: 1.4697 - val_acc: 0.7411\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 1.5121 - acc: 0.7313 - val_loss: 1.4331 - val_acc: 0.7514\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 1.5134 - acc: 0.7348 - val_loss: 1.6831 - val_acc: 0.7006\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 1.5154 - acc: 0.7379 - val_loss: 1.3996 - val_acc: 0.7652\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 1.5171 - acc: 0.7354 - val_loss: 1.3711 - val_acc: 0.7795\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 1.5177 - acc: 0.7336 - val_loss: 1.5133 - val_acc: 0.7357\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 37s 95ms/step - loss: 1.5199 - acc: 0.7336 - val_loss: 1.4756 - val_acc: 0.7579\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 1.5116 - acc: 0.7360 - val_loss: 1.3853 - val_acc: 0.7725\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.5142 - acc: 0.7359 - val_loss: 1.3672 - val_acc: 0.7862\n",
            "VALIDATION ACCURACY AFTER 4 ITERATIONS = 0.7862\n",
            "ITERATION 5 \n",
            "Deleting 4/44 channels from layer: conv2d_14\n",
            "Deleting 4/44 channels from layer: conv2d_15\n",
            "Deleting 8/86 channels from layer: conv2d_16\n",
            "Deleting 8/86 channels from layer: conv2d_17\n",
            "Deleting 17/170 channels from layer: conv2d_18\n",
            "Deleting 17/170 channels from layer: conv2d_19\n",
            "Deleting 17/170 channels from layer: conv2d_20\n",
            "Deleting 33/337 channels from layer: conv2d_21\n",
            "Deleting 33/337 channels from layer: conv2d_22\n",
            "Deleting 33/337 channels from layer: conv2d_23\n",
            "Deleting 33/337 channels from layer: conv2d_24\n",
            "Deleting 33/337 channels from layer: conv2d_25\n",
            "Deleting 33/337 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 49s 124ms/step - loss: 1.5085 - acc: 0.7143 - val_loss: 1.3980 - val_acc: 0.7656\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.5195 - acc: 0.7217 - val_loss: 1.5422 - val_acc: 0.7318\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.5184 - acc: 0.7256 - val_loss: 1.4798 - val_acc: 0.7291\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 1.5105 - acc: 0.7277 - val_loss: 1.3786 - val_acc: 0.7626\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.5048 - acc: 0.7259 - val_loss: 1.3556 - val_acc: 0.7781\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 1.5037 - acc: 0.7280 - val_loss: 1.3799 - val_acc: 0.7705\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5015 - acc: 0.7305 - val_loss: 1.5325 - val_acc: 0.7237\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 1.5056 - acc: 0.7283 - val_loss: 1.4110 - val_acc: 0.7563\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 1.4991 - acc: 0.7296 - val_loss: 1.3445 - val_acc: 0.7747\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 1.5074 - acc: 0.7295 - val_loss: 1.4672 - val_acc: 0.7438\n",
            "VALIDATION ACCURACY AFTER 5 ITERATIONS = 0.7781\n",
            "ITERATION 6 \n",
            "Deleting 4/40 channels from layer: conv2d_14\n",
            "Deleting 4/40 channels from layer: conv2d_15\n",
            "Deleting 7/78 channels from layer: conv2d_16\n",
            "Deleting 7/78 channels from layer: conv2d_17\n",
            "Deleting 15/153 channels from layer: conv2d_18\n",
            "Deleting 15/153 channels from layer: conv2d_19\n",
            "Deleting 15/153 channels from layer: conv2d_20\n",
            "Deleting 30/304 channels from layer: conv2d_21\n",
            "Deleting 30/304 channels from layer: conv2d_22\n",
            "Deleting 30/304 channels from layer: conv2d_23\n",
            "Deleting 30/304 channels from layer: conv2d_24\n",
            "Deleting 30/304 channels from layer: conv2d_25\n",
            "Deleting 30/304 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 1.4993 - acc: 0.7050 - val_loss: 1.4808 - val_acc: 0.7472\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 1.5089 - acc: 0.7156 - val_loss: 1.4222 - val_acc: 0.7440\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 34s 87ms/step - loss: 1.5050 - acc: 0.7202 - val_loss: 1.3558 - val_acc: 0.7655\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 34s 87ms/step - loss: 1.4935 - acc: 0.7199 - val_loss: 1.4274 - val_acc: 0.7466\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 34s 86ms/step - loss: 1.4910 - acc: 0.7218 - val_loss: 1.4346 - val_acc: 0.7383\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 33s 86ms/step - loss: 1.4964 - acc: 0.7214 - val_loss: 1.3064 - val_acc: 0.7807\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 34s 86ms/step - loss: 1.4974 - acc: 0.7222 - val_loss: 1.4418 - val_acc: 0.7479\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 33s 85ms/step - loss: 1.4954 - acc: 0.7244 - val_loss: 1.4143 - val_acc: 0.7515\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 1.4993 - acc: 0.7228 - val_loss: 1.6445 - val_acc: 0.6926\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 33s 85ms/step - loss: 1.4939 - acc: 0.7245 - val_loss: 1.3877 - val_acc: 0.7549\n",
            "VALIDATION ACCURACY AFTER 6 ITERATIONS = 0.7807\n",
            "ITERATION 7 \n",
            "Deleting 3/36 channels from layer: conv2d_14\n",
            "Deleting 3/36 channels from layer: conv2d_15\n",
            "Deleting 7/71 channels from layer: conv2d_16\n",
            "Deleting 7/71 channels from layer: conv2d_17\n",
            "Deleting 13/138 channels from layer: conv2d_18\n",
            "Deleting 13/138 channels from layer: conv2d_19\n",
            "Deleting 13/138 channels from layer: conv2d_20\n",
            "Deleting 27/274 channels from layer: conv2d_21\n",
            "Deleting 27/274 channels from layer: conv2d_22\n",
            "Deleting 27/274 channels from layer: conv2d_23\n",
            "Deleting 27/274 channels from layer: conv2d_24\n",
            "Deleting 27/274 channels from layer: conv2d_25\n",
            "Deleting 27/274 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 48s 123ms/step - loss: 1.4891 - acc: 0.7034 - val_loss: 1.4333 - val_acc: 0.7282\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 34s 86ms/step - loss: 1.5071 - acc: 0.7094 - val_loss: 1.4559 - val_acc: 0.7368\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 34s 86ms/step - loss: 1.5036 - acc: 0.7101 - val_loss: 1.3577 - val_acc: 0.7556\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 34s 87ms/step - loss: 1.4985 - acc: 0.7153 - val_loss: 1.4127 - val_acc: 0.7426\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 34s 86ms/step - loss: 1.5016 - acc: 0.7152 - val_loss: 1.5883 - val_acc: 0.6928\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 34s 87ms/step - loss: 1.4931 - acc: 0.7148 - val_loss: 1.4078 - val_acc: 0.7497\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 34s 87ms/step - loss: 1.4909 - acc: 0.7159 - val_loss: 1.4484 - val_acc: 0.7178\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 34s 87ms/step - loss: 1.4975 - acc: 0.7140 - val_loss: 1.3378 - val_acc: 0.7634\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 34s 87ms/step - loss: 1.4956 - acc: 0.7170 - val_loss: 1.4800 - val_acc: 0.7228\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 34s 86ms/step - loss: 1.4997 - acc: 0.7140 - val_loss: 1.3456 - val_acc: 0.7646\n",
            "VALIDATION ACCURACY AFTER 7 ITERATIONS = 0.7646\n",
            "ITERATION 8 \n",
            "Deleting 3/33 channels from layer: conv2d_14\n",
            "Deleting 3/33 channels from layer: conv2d_15\n",
            "Deleting 6/64 channels from layer: conv2d_16\n",
            "Deleting 6/64 channels from layer: conv2d_17\n",
            "Deleting 12/125 channels from layer: conv2d_18\n",
            "Deleting 12/125 channels from layer: conv2d_19\n",
            "Deleting 12/125 channels from layer: conv2d_20\n",
            "Deleting 24/247 channels from layer: conv2d_21\n",
            "Deleting 24/247 channels from layer: conv2d_22\n",
            "Deleting 24/247 channels from layer: conv2d_23\n",
            "Deleting 24/247 channels from layer: conv2d_24\n",
            "Deleting 24/247 channels from layer: conv2d_25\n",
            "Deleting 24/247 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 45s 116ms/step - loss: 1.5021 - acc: 0.6910 - val_loss: 1.4267 - val_acc: 0.7312\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 1.5046 - acc: 0.7004 - val_loss: 1.6122 - val_acc: 0.6855\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 1.5065 - acc: 0.7030 - val_loss: 1.3347 - val_acc: 0.7570\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 31s 78ms/step - loss: 1.4991 - acc: 0.7049 - val_loss: 1.3623 - val_acc: 0.7523\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 31s 78ms/step - loss: 1.4926 - acc: 0.7064 - val_loss: 1.4374 - val_acc: 0.7273\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 1.4930 - acc: 0.7084 - val_loss: 1.3880 - val_acc: 0.7328\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 1.4842 - acc: 0.7094 - val_loss: 1.3659 - val_acc: 0.7462\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 31s 78ms/step - loss: 1.4968 - acc: 0.7074 - val_loss: 1.3280 - val_acc: 0.7614\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 31s 79ms/step - loss: 1.4946 - acc: 0.7078 - val_loss: 1.4051 - val_acc: 0.7443\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 1.4979 - acc: 0.7062 - val_loss: 1.3321 - val_acc: 0.7663\n",
            "VALIDATION ACCURACY AFTER 8 ITERATIONS = 0.7663\n",
            "ITERATION 9 \n",
            "Deleting 3/30 channels from layer: conv2d_14\n",
            "Deleting 3/30 channels from layer: conv2d_15\n",
            "Deleting 5/58 channels from layer: conv2d_16\n",
            "Deleting 5/58 channels from layer: conv2d_17\n",
            "Deleting 11/113 channels from layer: conv2d_18\n",
            "Deleting 11/113 channels from layer: conv2d_19\n",
            "Deleting 11/113 channels from layer: conv2d_20\n",
            "Deleting 22/223 channels from layer: conv2d_21\n",
            "Deleting 22/223 channels from layer: conv2d_22\n",
            "Deleting 22/223 channels from layer: conv2d_23\n",
            "Deleting 22/223 channels from layer: conv2d_24\n",
            "Deleting 22/223 channels from layer: conv2d_25\n",
            "Deleting 22/223 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 1.5111 - acc: 0.6781 - val_loss: 1.4024 - val_acc: 0.7233\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.5136 - acc: 0.6904 - val_loss: 1.5729 - val_acc: 0.6903\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.4989 - acc: 0.6965 - val_loss: 1.3571 - val_acc: 0.7400\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 1.4964 - acc: 0.6981 - val_loss: 1.4538 - val_acc: 0.7181\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.4988 - acc: 0.6960 - val_loss: 1.3175 - val_acc: 0.7533\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 1.4939 - acc: 0.6992 - val_loss: 1.3060 - val_acc: 0.7595\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.5053 - acc: 0.6957 - val_loss: 1.3478 - val_acc: 0.7436\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.4898 - acc: 0.7017 - val_loss: 1.4972 - val_acc: 0.6966\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.4938 - acc: 0.6972 - val_loss: 1.3082 - val_acc: 0.7575\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.4916 - acc: 0.6989 - val_loss: 1.4743 - val_acc: 0.7093\n",
            "VALIDATION ACCURACY AFTER 9 ITERATIONS = 0.7595\n",
            "ITERATION 10 \n",
            "Deleting 2/27 channels from layer: conv2d_14\n",
            "Deleting 2/27 channels from layer: conv2d_15\n",
            "Deleting 5/53 channels from layer: conv2d_16\n",
            "Deleting 5/53 channels from layer: conv2d_17\n",
            "Deleting 10/102 channels from layer: conv2d_18\n",
            "Deleting 10/102 channels from layer: conv2d_19\n",
            "Deleting 10/102 channels from layer: conv2d_20\n",
            "Deleting 20/201 channels from layer: conv2d_21\n",
            "Deleting 20/201 channels from layer: conv2d_22\n",
            "Deleting 20/201 channels from layer: conv2d_23\n",
            "Deleting 20/201 channels from layer: conv2d_24\n",
            "Deleting 20/201 channels from layer: conv2d_25\n",
            "Deleting 20/201 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 47s 122ms/step - loss: 1.4983 - acc: 0.6740 - val_loss: 1.3476 - val_acc: 0.7270\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 1.5100 - acc: 0.6808 - val_loss: 1.5127 - val_acc: 0.6828\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 1.4991 - acc: 0.6846 - val_loss: 1.3621 - val_acc: 0.7329\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 1.5026 - acc: 0.6852 - val_loss: 1.3770 - val_acc: 0.7302\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 1.4874 - acc: 0.6894 - val_loss: 1.4330 - val_acc: 0.7116\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 1.4950 - acc: 0.6901 - val_loss: 1.3682 - val_acc: 0.7338\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 1.5033 - acc: 0.6873 - val_loss: 1.3920 - val_acc: 0.7136\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 1.4915 - acc: 0.6903 - val_loss: 1.3839 - val_acc: 0.7208\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.4917 - acc: 0.6904 - val_loss: 1.3170 - val_acc: 0.7421\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.4867 - acc: 0.6898 - val_loss: 1.3603 - val_acc: 0.7318\n",
            "VALIDATION ACCURACY AFTER 10 ITERATIONS = 0.7421\n",
            "ITERATION 11 \n",
            "Deleting 2/25 channels from layer: conv2d_14\n",
            "Deleting 2/25 channels from layer: conv2d_15\n",
            "Deleting 4/48 channels from layer: conv2d_16\n",
            "Deleting 4/48 channels from layer: conv2d_17\n",
            "Deleting 9/92 channels from layer: conv2d_18\n",
            "Deleting 9/92 channels from layer: conv2d_19\n",
            "Deleting 9/92 channels from layer: conv2d_20\n",
            "Deleting 18/181 channels from layer: conv2d_21\n",
            "Deleting 18/181 channels from layer: conv2d_22\n",
            "Deleting 18/181 channels from layer: conv2d_23\n",
            "Deleting 18/181 channels from layer: conv2d_24\n",
            "Deleting 18/181 channels from layer: conv2d_25\n",
            "Deleting 18/181 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 46s 118ms/step - loss: 1.5092 - acc: 0.6575 - val_loss: 1.4147 - val_acc: 0.7048\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 1.5126 - acc: 0.6709 - val_loss: 1.5657 - val_acc: 0.6615\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 1.5114 - acc: 0.6726 - val_loss: 1.3250 - val_acc: 0.7371\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 1.5157 - acc: 0.6750 - val_loss: 1.2985 - val_acc: 0.7441\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 1.5017 - acc: 0.6771 - val_loss: 1.3451 - val_acc: 0.7226\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.5019 - acc: 0.6753 - val_loss: 1.3079 - val_acc: 0.7395\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.5037 - acc: 0.6737 - val_loss: 1.5216 - val_acc: 0.6838\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.4945 - acc: 0.6786 - val_loss: 1.3281 - val_acc: 0.7354\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 1.4851 - acc: 0.6791 - val_loss: 1.2962 - val_acc: 0.7397\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 1.4910 - acc: 0.6784 - val_loss: 1.5357 - val_acc: 0.6714\n",
            "VALIDATION ACCURACY AFTER 11 ITERATIONS = 0.7441\n",
            "ITERATION 12 \n",
            "Deleting 2/23 channels from layer: conv2d_14\n",
            "Deleting 2/23 channels from layer: conv2d_15\n",
            "Deleting 4/44 channels from layer: conv2d_16\n",
            "Deleting 4/44 channels from layer: conv2d_17\n",
            "Deleting 8/83 channels from layer: conv2d_18\n",
            "Deleting 8/83 channels from layer: conv2d_19\n",
            "Deleting 8/83 channels from layer: conv2d_20\n",
            "Deleting 16/163 channels from layer: conv2d_21\n",
            "Deleting 16/163 channels from layer: conv2d_22\n",
            "Deleting 16/163 channels from layer: conv2d_23\n",
            "Deleting 16/163 channels from layer: conv2d_24\n",
            "Deleting 16/163 channels from layer: conv2d_25\n",
            "Deleting 16/163 channels from layer: conv2d_26\n",
            "0 conv2d_14\n",
            "4 conv2d_15\n",
            "8 conv2d_16\n",
            "12 conv2d_17\n",
            "16 conv2d_18\n",
            "20 conv2d_19\n",
            "24 conv2d_20\n",
            "28 conv2d_21\n",
            "32 conv2d_22\n",
            "36 conv2d_23\n",
            "40 conv2d_24\n",
            "44 conv2d_25\n",
            "48 conv2d_26\n",
            "54 dense_3\n",
            "Epoch 1/10\n",
            "390/390 [==============================] - 46s 118ms/step - loss: 1.5121 - acc: 0.6490 - val_loss: 1.2929 - val_acc: 0.7254\n",
            "Epoch 2/10\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.5097 - acc: 0.6598 - val_loss: 1.3622 - val_acc: 0.7057\n",
            "Epoch 3/10\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 1.5089 - acc: 0.6631 - val_loss: 1.3711 - val_acc: 0.7069\n",
            "Epoch 4/10\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 1.5078 - acc: 0.6658 - val_loss: 1.5593 - val_acc: 0.6469\n",
            "Epoch 5/10\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.5063 - acc: 0.6649 - val_loss: 1.4020 - val_acc: 0.6973\n",
            "Epoch 6/10\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 1.5147 - acc: 0.6647 - val_loss: 1.3899 - val_acc: 0.6995\n",
            "Epoch 7/10\n",
            "390/390 [==============================] - 28s 71ms/step - loss: 1.4993 - acc: 0.6665 - val_loss: 1.3781 - val_acc: 0.6977\n",
            "Epoch 8/10\n",
            "390/390 [==============================] - 31s 79ms/step - loss: 1.5077 - acc: 0.6631 - val_loss: 1.2969 - val_acc: 0.7324\n",
            "Epoch 9/10\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.4947 - acc: 0.6647 - val_loss: 1.3739 - val_acc: 0.7065\n",
            "Epoch 10/10\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.4958 - acc: 0.6656 - val_loss: 1.3337 - val_acc: 0.7147\n",
            "VALIDATION ACCURACY AFTER 12 ITERATIONS = 0.7324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF423qYy_UHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_df = pd.DataFrame(log_dict)\n",
        "log_df.to_csv('/content/drive/My Drive/RESULT_VGG_HISTORY_L1_PRUNING.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQn6n48IB2eL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}